{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from TPNN.tools.CNNarchitecture import *\n",
    "from TPNN.tools.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test net creation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers count: 5\n",
      "layers configuration: \n",
      "\n",
      "CNN layer\n",
      " input shape - (1, 10, 10); output shape - (2, 8, 8)\n",
      " cores: \n",
      "[0]:\n",
      "     0.7070407743116518 -0.0997372196300661 0.6922620576463498 \n",
      "     0.024788605506006478 -0.5869277953944796 -0.6130906721311149 \n",
      "     0.03617945689252222 -0.8413844919144033 -0.7242966865532816 \n",
      "[1]:\n",
      "     0.8613372814220874 0.32655416241858126 -0.31692686890454946 \n",
      "     0.33706205399243516 0.8689084304230359 -0.6709516557725015 \n",
      "     0.18495214839070373 0.11791648192236504 0.2085855085178805 \n",
      " biases: \n",
      "     -0.5727297431328475 0.3982584410567205 \n",
      "\n",
      "MaxPooling layer\n",
      " input shape - (2, 8, 8); output shape - (2, 4, 4)\n",
      " core shape: (2, 2)\n",
      " maximums positions:\n",
      "[[[[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]]]\n",
      "\n",
      "Reformat layer\n",
      " input shape - (2, 4, 4); output shape - (32,)\n",
      "\n",
      "Dense layer\n",
      " neuron count: 10\n",
      " input shape - (32,); output shape - (10,)\n",
      " weight matrix:\n",
      "     0.2717549433762265 0.21338206227773515 0.1324503567720381 0.9707912920773014 0.8959397325224614 -0.6786140409992365 0.00606693687203208 -0.6976245002396664 -0.08073318022243647 0.49401836905644125 \n",
      "     -0.5714461920802356 -0.31831741389062773 -0.324230904946158 -0.14263964422770758 0.4115108026424412 0.9655758971047146 -0.2075873459789528 -0.731085809640813 0.07141939697800637 0.12870838847496158 \n",
      "     -0.9518737463397127 0.7554945292524182 -0.45035586181639187 -0.49448623847632 0.13666881543808862 0.8954985464924226 -0.43153290785773146 0.6968392398080547 0.7716982954427947 0.3213780076707158 \n",
      "     -0.5567308307021261 0.34566407886373374 -0.6001805822391912 0.14425380996711512 -0.981569196514978 -0.12408463886051835 -0.5529817181955328 -0.8064142144501609 0.5863638402935034 0.23881546398900277 \n",
      "     0.808254350437621 -0.8839175120209564 -0.4615849132792851 0.8519464622947279 0.6265259727498249 -0.5167392900163281 0.9266169403239088 0.00683361609896882 -0.4964877365977767 0.7444507671294776 \n",
      "     0.07509806228019733 -0.4525909367181917 -0.5387366571592251 0.8554279666919773 0.531113789121568 -0.5948977422590118 0.90203570342747 -0.6931628289234681 0.5649813668763584 0.7103327859013591 \n",
      "     -0.45502336440325775 0.27898024264519017 0.10241420417322811 0.7853350292623376 -0.42917088925479074 -0.5956369389848846 -0.6407221254263125 -0.7007480256755536 -0.11143333010271639 0.757638160224614 \n",
      "     -0.16836552706571917 0.6822313561602777 0.244389575468978 0.3275937675381946 0.29803444756856856 -0.7657641655094163 0.3143522280284443 -0.8634013782984526 0.47680758655425826 -0.43120829149089146 \n",
      "     0.10211475749049259 -0.4234219295213837 -0.6694981287320114 0.48536384773933805 -0.8872284457886677 -0.560958722947557 -0.46932141841071906 0.06266216093653831 0.8249180445808493 -0.21737373503890844 \n",
      "     -0.8462990318016987 0.5320408830162353 -0.38073029324069463 0.4868059433935481 -0.009488989606654785 0.5887406000431634 0.09414924404150748 0.7339917087769015 0.962450224826644 -0.40608258554304544 \n",
      "     0.5149494220816739 0.9635640675764057 -0.4329630252767702 0.29321000658564844 -0.8056417502546933 0.7022578794089287 0.31277455573883617 0.20430283257739235 0.4187730690971452 0.9560458550873077 \n",
      "     0.6334768731332701 -0.09241540970713724 -0.7994834256307319 0.9929926358813035 0.6206275642271295 -0.26525290059486095 0.7471462615635112 -0.2373307556667843 0.25039198661756323 -0.1737734142261742 \n",
      "     0.021132916335873997 -0.8325511958638114 -0.04018615144661708 -0.055207758113244854 0.8365032527518703 0.4071963548340485 -0.09412307915686946 0.18457688592867671 0.8237517616170889 0.36185518168394326 \n",
      "     0.5743806457113154 -0.3653703271456785 -0.25952358085860006 -0.33534915670732457 0.9401857895666073 0.14840814307080907 0.4513877243653679 0.9413204397995067 -0.716228920844985 -0.30794994364835193 \n",
      "     -0.8933848095187444 -0.4186219958604793 0.7068734558503427 -0.763267745056381 0.6947506373568604 0.05143718299256217 0.9987731120194845 -0.11371014249901235 -0.17758209158323934 -0.39769885340203426 \n",
      "     -0.38202042313525264 -0.6732322343389283 0.12156283415300861 -0.8529930095675955 -0.8056456872105249 -0.6441397232300186 -0.3727297997798069 0.06649320158480143 -0.21691880823150567 -0.8419908454822147 \n",
      "     0.9158830732727019 0.301164840816297 0.8894694582624472 -0.9246159749453404 -0.4443194166785822 -0.08877117693567405 0.03313732750818277 -0.3668837294044962 -0.7899548642106493 -0.04005412707237199 \n",
      "     -0.7183230043405977 0.8276933944649423 0.514945133665901 -0.7628366246596954 -0.39703003061200626 0.030427728089617467 0.32492947968040986 0.8876942153270169 -0.3399522424753707 0.9110819060692084 \n",
      "     -0.7822383975310072 0.7375637787055485 0.5140161849022868 -0.9075994603431368 -0.44922678248621106 0.9197190951350607 -0.5160220457903417 0.7350937607766685 -0.1725731065464109 -0.9270917954771702 \n",
      "     -0.1861140532288077 -0.48225823237013254 -0.3419105595860823 0.9296877338727751 0.6198506421295817 -0.523351083891495 0.458823934541551 0.45124022177376166 0.46462719103122674 0.5776678217673066 \n",
      "     0.09763663905329723 -0.69293423503202 -0.651196345422181 0.9992060485355105 0.13434354495763 0.6816599222129454 -0.4118899101434381 0.10713831464525114 0.3736711850729122 0.5933245616718419 \n",
      "     -0.0793036752324916 -0.24079429464064073 -0.6789430650886386 0.6257249868607335 -0.6151607833212247 -0.1684056804367564 -0.6245966439177337 0.2832213204233127 0.1697667305923436 0.3818903731554828 \n",
      "     -0.005883348944398792 0.32649733554940696 -0.13649797821374898 -0.3317110028269743 -0.7079950710081233 0.28423929690907457 0.7575425260622943 -0.12339782016999257 -0.6616647417801305 0.7902865589772792 \n",
      "     0.01883731328312077 -0.5049083623063071 -0.6550487982216298 -0.240968157776968 -0.008380360303289924 0.36267437930951196 0.30985800999156266 -0.036192624631892434 0.18382383703341243 0.38245581433905484 \n",
      "     -0.2519400585618745 -0.7695109994404692 -0.5525243444030485 -0.5151761513669897 0.28280196430411064 -0.9986696896545664 -0.9123347677908014 -0.823893351609774 0.2586899072030935 0.9748014595731924 \n",
      "     0.14348763952768762 -0.5830278435976375 0.002431969911052878 -0.3763354610753935 -0.8746687478739046 -0.7987102225787908 0.7926113175540455 0.28724424482318733 0.9277873019644602 0.31186045269375495 \n",
      "     -0.7474440902651145 0.8391820048086283 -0.8151634461136092 0.577368025207244 -0.9041950443236497 -0.102711674176857 -0.04945082822107927 -0.3227073883972087 -0.3236215330029977 -0.9643947312113745 \n",
      "     -0.15085871972516518 0.08892796473284825 -0.45247019651333753 -0.44722948061817536 -0.9335561555745222 -0.20669532884318187 0.45244114419302073 -0.39000873920879875 -0.7634081610379826 -0.7794574244816261 \n",
      "     0.13861090823540145 0.7699835075344204 -0.29879674307508575 0.8085951145815078 -0.29571355830590695 -0.02381812726656163 -0.2100659137421632 0.6949475728957524 -0.8049701242853009 -0.05634587553273218 \n",
      "     0.7316723675606838 -0.14233056779193065 -0.2782381841559467 0.2239225789110486 0.8717420568371435 0.16378099753499353 -0.5655055264967561 0.3853792397862159 -0.3752640132949032 0.49187353695073277 \n",
      "     0.24375848023673274 -0.917977608183824 -0.1597293276401872 0.5190029901965028 -0.5928941461338657 -0.05775605798708816 -0.11970088375657029 0.8466191667413718 0.7141693414081642 0.9156680543129532 \n",
      "     0.6493149532894988 -0.4754331487494625 -0.8221862994258151 -0.11988201230331552 -0.04247059958502142 0.9932055454590314 -0.8926515214486042 -0.2540860663914162 0.04642555944852367 0.995989188193994 \n",
      " biases vector: \n",
      "     0.9079297003106467 0.9514466487924912 0.9880127543449821 0.5979245174423724 0.7110266640999763 0.6695088045430664 0.4625757051084898 0.4786131210567294 0.104479368062806 0.0808030064587818 \n",
      "\n",
      "Softmax layer\n",
      " input shape - (10,); output shape - (10,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create net:\n",
    "cnnLayer = CNNlayer((1, 10, 10), sigmoid, 2, (3,3), 1)\n",
    "poolingLayer = MaxPoolingLayer((2,2), cnnLayer.output_shape)\n",
    "reformatLayer = ReformatLayer(poolingLayer.output_shape)\n",
    "denseLayer = DenseLayer(sigmoid, 10, reformatLayer.output_shape[0])\n",
    "softmaxLayer = SoftmaxLayer(10)\n",
    "\n",
    "net = Net()\n",
    "net.add_layer(cnnLayer)\n",
    "net.add_layer(poolingLayer)\n",
    "net.add_layer(reformatLayer)\n",
    "net.add_layer(denseLayer)\n",
    "net.add_layer(softmaxLayer)\n",
    "net.print_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "[[[0.54664461 0.49488608 0.95401174 0.19279533 0.10489976 0.59196797\n",
      "   0.49046557 0.90683631 0.10140715 0.97010112]\n",
      "  [0.70843652 0.096177   0.95622743 0.67801812 0.44193228 0.4515971\n",
      "   0.57464976 0.41650927 0.90973637 0.60015517]\n",
      "  [0.31105869 0.98972876 0.14653339 0.606798   0.5102243  0.02221437\n",
      "   0.26952732 0.67044132 0.98605945 0.54829919]\n",
      "  [0.20008519 0.96763605 0.66848164 0.83062202 0.17997199 0.87465754\n",
      "   0.26994607 0.58203362 0.81408389 0.69738703]\n",
      "  [0.68851994 0.94770846 0.83487305 0.33497106 0.78167657 0.42726741\n",
      "   0.09180004 0.47719111 0.08699672 0.4811421 ]\n",
      "  [0.4673319  0.24829895 0.70106331 0.27239271 0.15703104 0.25653733\n",
      "   0.96040735 0.5355516  0.27479525 0.64728506]\n",
      "  [0.63638602 0.34284641 0.72745579 0.16515132 0.31020975 0.55002303\n",
      "   0.17733864 0.31809568 0.10974023 0.79932567]\n",
      "  [0.06096947 0.48817163 0.05713495 0.748674   0.78935411 0.550996\n",
      "   0.65306401 0.07357814 0.39396841 0.14629229]\n",
      "  [0.78173637 0.92586507 0.02147337 0.30373761 0.44632917 0.15379916\n",
      "   0.69344117 0.4488574  0.37367576 0.98069505]\n",
      "  [0.76796589 0.21585308 0.6493021  0.72255263 0.06585649 0.74241144\n",
      "   0.09916393 0.09010493 0.24837437 0.46861002]]]\n"
     ]
    }
   ],
   "source": [
    "input_data = np.random.rand(1, 10, 10)\n",
    "\n",
    "print(\"input:\")\n",
    "print(input_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result shape: (32,)\n",
      "[0.09288644 0.09570438 0.05869583 0.11845946 0.06566501 0.10053165\n",
      " 0.10393501 0.12508784 0.09901072 0.14002366]\n"
     ]
    }
   ],
   "source": [
    "print(net.get_output(input_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test CNN layer output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "[[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]]\n",
      "net config\n",
      "Layers count: 1\n",
      "layers configuration: \n",
      "\n",
      "CNN layer\n",
      " input shape - (2, 4, 4); output shape - (2, 2, 2)\n",
      " cores: \n",
      "[0]:\n",
      "     1.0 0.0 \n",
      "     0.0 1.0 \n",
      "[1]:\n",
      "     1.0 0.0 \n",
      "     0.0 1.0 \n",
      " biases: \n",
      "     1 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_info(input, net):\n",
    "    print(\"input:\")\n",
    "    print(input)\n",
    "    print(\"net config\")\n",
    "    net.print_config()\n",
    "\n",
    "cnnLayer = CNNlayer((2,4,4), ident, 2, (2,2), 2)\n",
    "cores = np.array([np.eye(2), np.eye(2)])\n",
    "cnnLayer.set_cores(cores)\n",
    "cnnLayer.set_biases(np.array([1, 1]))\n",
    "\n",
    "net = Net()\n",
    "net.add_layer(cnnLayer)\n",
    "\n",
    "input = np.array([np.eye(4),np.eye(4)])\n",
    "\n",
    "print_info(input, net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5. 1.]\n",
      "  [1. 5.]]\n",
      "\n",
      " [[5. 1.]\n",
      "  [1. 5.]]]\n"
     ]
    }
   ],
   "source": [
    "print(net.get_output(input))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test pooling layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "[[[1 2 1 2]\n",
      "  [1 2 1 2]\n",
      "  [1 2 1 2]\n",
      "  [1 2 1 2]]\n",
      "\n",
      " [[1 2 1 2]\n",
      "  [1 2 1 2]\n",
      "  [1 2 1 2]\n",
      "  [1 2 1 2]]]\n",
      "net config\n",
      "Layers count: 1\n",
      "layers configuration: \n",
      "\n",
      "MaxPooling layer\n",
      " input shape - (2, 4, 4); output shape - (2, 2, 2)\n",
      " core shape: (2, 2)\n",
      " maximums positions:\n",
      "[[[[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "poolingLayer = MaxPoolingLayer((2,2), (2,4,4))\n",
    "net.add_layer(poolingLayer)\n",
    "\n",
    "input = np.array([[[1,2,1,2], [1,2,1,2], [1,2,1,2], [1,2,1,2]], [[1,2,1,2], [1,2,1,2], [1,2,1,2], [1,2,1,2]]])\n",
    "\n",
    "print_info(input, net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2. 2.]\n",
      "  [2. 2.]]\n",
      "\n",
      " [[2. 2.]\n",
      "  [2. 2.]]]\n"
     ]
    }
   ],
   "source": [
    "print(net.get_output(input))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test dense layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "net config\n",
      "Layers count: 1\n",
      "layers configuration: \n",
      "\n",
      "Dense layer\n",
      " neuron count: 10\n",
      " input shape - (10,); output shape - (10,)\n",
      " weight matrix:\n",
      "     1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "     0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "     0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "     0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "     0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 \n",
      "     0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 \n",
      "     0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 \n",
      "     0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 \n",
      "     0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 \n",
      "     0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 \n",
      " biases vector: \n",
      "     0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "denseLayer = DenseLayer(ident, 10, 10)\n",
    "denseLayer.set_weighs(np.eye(10))\n",
    "denseLayer.set_biases(np.zeros((10, 1)))\n",
    "\n",
    "net = Net()\n",
    "net.add_layer(denseLayer)\n",
    "\n",
    "input = np.arange(0,10)\n",
    "\n",
    "print_info(input, net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_output(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test reformat layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]]\n",
      "net config\n",
      "Layers count: 1\n",
      "layers configuration: \n",
      "\n",
      "Reformat layer\n",
      " input shape - (2, 4, 4); output shape - (32,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "reformatLayer = ReformatLayer((2, 4, 4))\n",
    "net.add_layer(reformatLayer)\n",
    "\n",
    "input = np.ones((2,4,4))\n",
    "\n",
    "print_info(input, net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result shape: (32,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_output(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test softmax layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "net config\n",
      "Layers count: 1\n",
      "layers configuration: \n",
      "\n",
      "Softmax layer\n",
      " input shape - (10,); output shape - (10,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "softmaxLayer = SoftmaxLayer(10)\n",
    "net.add_layer(softmaxLayer)\n",
    "\n",
    "input = np.arange(1, 11)\n",
    "print_info(input, net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.80134161e-05 2.12062451e-04 5.76445508e-04 1.56694135e-03\n",
      " 4.25938820e-03 1.15782175e-02 3.14728583e-02 8.55520989e-02\n",
      " 2.32554716e-01 6.32149258e-01]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "output = net.get_output(input)\n",
    "print(output)\n",
    "print(np.sum(output))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0]:\n",
      "    [0]:\n",
      "          [0]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [1]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [2]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "    [1]:\n",
      "          [0]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [1]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [2]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "    [2]:\n",
      "          [0]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [1]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [2]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      " [1]:\n",
      "    [0]:\n",
      "          [0]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [1]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [2]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "    [1]:\n",
      "          [0]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [1]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [2]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "    [2]:\n",
      "          [0]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [1]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [2]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      " [2]:\n",
      "    [0]:\n",
      "          [0]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [1]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [2]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "    [1]:\n",
      "          [0]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [1]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [2]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "    [2]:\n",
      "          [0]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [1]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n",
      "          [2]:\n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "                   0.0 0.0 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from TPNN.tools.functions import print_arrays\n",
    "arr = np.zeros((3,3,3,3,3))\n",
    "print_arrays(arr, \" \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers count: 5\n",
      "layers configuration: \n",
      "\n",
      "CNN layer\n",
      " input shape - (2, 10, 10); output shape - (2, 8, 8)\n",
      " cores: \n",
      "[0]:\n",
      "     -0.7907793943410741 0.3246140217169706 -0.48421392757126336 \n",
      "     0.09200887909501132 0.41592903011032956 -0.4384271079066655 \n",
      "     0.9063566463635373 0.5482427673853383 0.09246946684982182 \n",
      "[1]:\n",
      "     0.33128836782290016 -0.7842896268029247 -0.20804913633466238 \n",
      "     -0.8564059728646036 -0.7247790285363589 0.411954763158636 \n",
      "     -0.18683967116331823 -0.47573456839754424 0.006187297568420513 \n",
      " biases: \n",
      "     0.5401230585655652 0.5165421850741263 \n",
      "\n",
      "MaxPooling layer\n",
      " input shape - (2, 8, 8); output shape - (2, 4, 4)\n",
      " core shape: (2, 2)\n",
      " maximums positions:\n",
      "[[[[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]\n",
      "   [0. 0.]]]]\n",
      "\n",
      "Reformat layer\n",
      " input shape - (2, 4, 4); output shape - (32,)\n",
      "\n",
      "Dense layer\n",
      " neuron count: 10\n",
      " input shape - (32,); output shape - (10,)\n",
      " weight matrix:\n",
      "     -0.2944256718333276 -0.6115107278674696 0.5996408493807466 -0.9830280141510566 -0.9527880524288121 0.9233918187174601 -0.4295767858706616 -0.12991203643047156 -0.4487503675339344 0.4751508312033179 \n",
      "     -0.8754166467751181 -0.7781261797130348 0.7488896618239864 -0.9297491606074098 0.6293325724089569 -0.31346060220805994 0.25684837365142665 0.6766596736087807 0.06013182056984223 -0.4058342163732842 \n",
      "     -0.49068816727653886 -0.5867743175684428 -0.5291900710366462 0.8992186384556586 0.13640636488445468 -0.6415439022273857 -0.40333940712960303 -0.24377243190976294 -0.9717489292902695 -0.6028569087786437 \n",
      "     0.19784616484854056 0.1772938129792887 -0.27214832154534285 -0.407644326220685 0.6024377900467119 -0.593923285463714 -0.9356057681516496 0.7696233930666851 0.8915287671575511 0.9760046344794497 \n",
      "     -0.8562533345334775 -0.12164329553330844 -0.2975507265498931 -0.23077478409121088 -0.16689719549311777 -0.6807141960864718 0.1953679643284001 0.6741671635098179 -0.9223271424768511 0.8532711101128929 \n",
      "     -0.2541778268479713 0.13569237971652148 0.8725419881995045 -0.6036821512173169 -0.5270497230631914 0.45357629353366047 0.25714120051414846 -0.047300286339032604 -0.4457822329437824 -0.7847213056585589 \n",
      "     -0.6979705781947669 0.8673157250698169 0.38201226362833096 0.8643661504167759 -0.7901282874198186 0.740175597532716 0.423967805251128 -0.6602754235634936 0.38814376372739323 -0.62881641988052 \n",
      "     -0.8655704741539396 0.732694721679052 0.6280815145540757 -0.044083139039530206 -0.985819855168548 0.677897361217918 0.8980898982462242 -0.7337941815750519 -0.5701638793510613 -0.5685654389929917 \n",
      "     0.773165669223767 0.40916407284709244 -0.15910968055366426 -0.7919989412821331 -0.6336255961439226 -0.3035051489049767 -0.208525518120928 0.30936902970766567 0.8009285915912518 0.5718387926429607 \n",
      "     0.3231089156041804 -0.40287135840064003 0.37700113844443806 -0.5950938441869167 0.990467495582473 0.7665372524826299 -0.509094239406032 0.07718536740767035 -0.3214544464688067 -0.845458807855515 \n",
      "     0.3318199773602075 0.9035142257465365 -0.006797622500352984 -0.3878364769450251 -0.2579693548173052 -0.7327314286566109 0.5806156950545258 -0.34612144485478824 0.5212793101683431 0.6229621632043885 \n",
      "     0.8035714669196417 0.8106316406724765 0.1649363387488152 0.8142618065869227 -0.7613393424781405 -0.2582233995047565 -0.1803318248484267 -0.6179662983954131 0.3618928851580314 0.6282035132988633 \n",
      "     0.19756376645603835 -0.6610654864405896 -0.9320687557442251 -0.32218077518766797 -0.7270637170226066 0.2233822792028517 0.4549096242559063 0.32174234848502414 -0.475309112287716 0.4856068662372268 \n",
      "     -0.21511095892916 -0.6102435573783052 -0.22302245785736607 0.9622566715876539 0.6821042061650431 -0.3105290435358221 -0.3339860559839991 0.8627344381844819 -0.9469253036246585 0.2588999725455927 \n",
      "     0.49792909988423184 0.0794049157766139 0.4199349734119646 0.035551404497767836 0.15820298416430245 -0.45473836830773684 0.46203596395507973 -0.9821833789757306 0.5322775752956643 0.528389607958083 \n",
      "     -0.0854554536874983 -0.5987952895270618 -0.08585783753018483 0.9996334561882165 -0.769046078959541 -0.25790608018435757 0.15780830676225888 -0.9997367823004439 -0.44296055054756955 -0.7960766862897997 \n",
      "     -0.45394550900526287 -0.9195910316947844 0.7147995790946791 -0.005034332369583838 0.23562482611532398 -0.4751835441098786 -0.45625696360090084 0.5531917289401151 -0.484752688834285 0.11524218155924326 \n",
      "     0.19929789154952937 -0.6987439162642777 -0.4383983464118799 0.871730109811903 -0.397774949668378 -0.2664015868510319 -0.6585448424987468 0.5849923434886464 0.15407207492730146 0.8596602307228955 \n",
      "     0.7541800164274186 0.34527041690436233 0.1304759716444308 0.06246010956819026 0.47917022800612585 -0.7610136417579016 0.9026571399895913 -0.12100444682499778 -0.4213473162867001 -0.016842304905813732 \n",
      "     0.42285464992865807 -0.20506299475720158 0.26392817834614535 -0.680403763586894 -0.5640978604095164 0.3998559292461503 -0.022308551152219414 0.9189888675636797 0.5265031143641707 0.9904978288983386 \n",
      "     0.4344013868038299 0.9321163182732495 0.7674796787726683 0.04150815872630376 0.737173182715007 0.6289794683283327 0.3204530445072511 -0.8041207627106972 -0.39170386179640215 0.8786861533608361 \n",
      "     0.8253579784940877 -0.40827015331204874 -0.3705408847097922 -0.5874911198240351 -0.14031224163040767 -0.5228810259993992 0.604087091529764 0.11652962570299397 0.38487704999842776 -0.977055094594987 \n",
      "     -0.6803957492629278 -0.4032276072677914 0.04291890523788333 -0.8947091080055412 -0.16427014879041146 -0.19282289995060364 0.11149566028471947 0.4406541783497706 -0.3463093727399196 -0.12303607783030812 \n",
      "     0.3100090301062992 0.6197667428168085 -0.9103828969430903 -0.8298313766542469 -0.08762630144156058 0.5844704444747726 0.9353735169553803 0.8262539915742446 -0.10881259251432018 -0.3789126462265604 \n",
      "     0.751047137147828 -0.008640452939589371 0.5540862161470437 0.49834715374951455 -0.9394406739326748 0.3069169607095461 -0.3152223653902575 -0.6402056631245443 0.6218560186388642 -0.15986573218168343 \n",
      "     0.5496564227793233 0.5130008850122498 -0.2657552884134169 -0.7185864195028866 -0.04055487588942874 -0.7555786148519057 -0.32851328160502136 -0.1987217820692586 0.4382455276248529 0.532055039667283 \n",
      "     0.41555470668364913 -0.4969811548796106 0.627154491288642 -0.8017958504363596 -0.49700283745785767 0.6168912771961479 0.6608842612668535 0.45768932059661704 -0.2292869571049856 -0.18191328545587693 \n",
      "     0.9592736825214294 0.16088441568935608 -0.11356955526868173 0.9202499125210508 0.45690296648872386 0.6603633908226738 0.7167671182615072 0.8351205876004659 -0.983305791934669 -0.8118491324755275 \n",
      "     0.9682881130153105 -0.7751007432438219 -0.9299221502798942 0.6119330245782348 -0.9728746967567381 0.26900845674225304 0.2785250018495309 -0.36641478873350297 0.9105051369116228 0.4575941492758484 \n",
      "     0.2698844301379011 0.9145981169097459 0.22958142870986342 -0.27411648098546926 -0.20446764272754647 -0.7690357891231261 -0.8804464424793061 -0.8931339145411965 0.9597378731679038 0.20933414941994277 \n",
      "     0.5159009495055604 0.8541921601304143 0.9301073911118956 -0.4873573343850981 -0.2859779214293934 -0.026550410960262782 -0.33905377557247096 0.2585457877823092 -0.37256804897330764 0.8907673767202822 \n",
      "     0.9758599296880712 0.6657777883036999 -0.08960011467357987 0.2127883816252396 -0.3513504824227329 0.08789817570635816 0.22778194490732973 -0.17028942192868302 0.7552403297135288 -0.14446302192302563 \n",
      " biases vector: \n",
      "     0.7272303399589681 0.7319529032391692 0.6638019136219409 0.9418790164391362 0.7782872348356958 0.32039361151510315 0.40957124575020953 0.24398275124143776 0.4213392742595693 0.48319848497932616 \n",
      "\n",
      "Softmax layer\n",
      " input shape - (10,); output shape - (10,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnnLayer = CNNlayer((2, 10, 10), sigmoid, 2, (3,3), 1)\n",
    "poolingLayer = MaxPoolingLayer((2,2), cnnLayer.output_shape)\n",
    "reformatLayer = ReformatLayer(poolingLayer.output_shape)\n",
    "denseLayer = DenseLayer(sigmoid, 10, reformatLayer.output_shape[0])\n",
    "softmaxLayer = SoftmaxLayer(10)\n",
    "\n",
    "net = Net()\n",
    "net.add_layer(cnnLayer)\n",
    "net.add_layer(poolingLayer)\n",
    "net.add_layer(reformatLayer)\n",
    "net.add_layer(denseLayer)\n",
    "net.add_layer(softmaxLayer)\n",
    "net.print_config()\n",
    "net.need_debug = True\n",
    "net.set_optimizer(Adam())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual vector:(10,)\n",
      "output vector:(10,)\n",
      "CNN layer\n",
      "  derivatives values:\n",
      "    input derivatives:\n",
      "      [0]:\n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "         0.0 0.0 0.0 -0.016584567669119643 0.009426447754728073 0.0 0.00744683710738192 -0.004676874620991329 0.0004682182452679267 0.0 \n",
      "         0.0 -0.002513190136835662 0.01148675300444877 -0.021488226094991042 0.005488381243905797 -0.0056360166633063835 0.010265789272716114 -0.00631775112617609 -9.875277036588105e-05 0.0 \n",
      "         0.0 0.0307665772978767 -0.005800591806764345 -0.014928801834552396 0.018697553519037177 -0.02584619394215027 0.030049746882626363 0.004978455953979886 0.0053723528356524365 0.0 \n",
      "         0.0 0.02217005012257766 3.464207962267882e-05 -0.013846580964974379 -0.0007534584694559568 -0.02809273837819961 -0.003379100091385784 -0.0077657166525473866 -0.0036077570023116596 0.0 \n",
      "         0.0 -0.009066296666389646 0.008810512742171797 0.027486718541165335 -0.018869410826248163 -0.037214656682625136 0.029684649641602178 -0.014321448958271987 0.015613713741875751 0.0 \n",
      "         0.0 -0.010933811945437357 -0.0016609548063011383 0.022464727025412114 0.001308341654652631 -0.036051737009314286 -0.0037377552191601563 -0.019582520065357777 -0.0034299665844459253 0.0 \n",
      "         0.0 -0.018306856382126663 0.004151263979884004 0.04862712051772605 -0.03382051855190042 0.028678080755792788 -0.015751911773070292 0.029464422456675465 -0.02135249826983656 0.0 \n",
      "         0.0 -0.0034956722757745265 0.0031288834280170934 0.04033991978595436 0.0025229740494029347 0.018076831549847953 -0.0005054415211766241 0.02561436604916159 0.0019373898161007 0.0 \n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "      [1]:\n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "         0.0 0.0 0.0 -0.016584567669119643 0.009426447754728073 0.0 0.00744683710738192 -0.004676874620991329 0.0004682182452679267 0.0 \n",
      "         0.0 -0.002513190136835662 0.01148675300444877 -0.021488226094991042 0.005488381243905797 -0.0056360166633063835 0.010265789272716114 -0.00631775112617609 -9.875277036588105e-05 0.0 \n",
      "         0.0 0.0307665772978767 -0.005800591806764345 -0.014928801834552396 0.018697553519037177 -0.02584619394215027 0.030049746882626363 0.004978455953979886 0.0053723528356524365 0.0 \n",
      "         0.0 0.02217005012257766 3.464207962267882e-05 -0.013846580964974379 -0.0007534584694559568 -0.02809273837819961 -0.003379100091385784 -0.0077657166525473866 -0.0036077570023116596 0.0 \n",
      "         0.0 -0.009066296666389646 0.008810512742171797 0.027486718541165335 -0.018869410826248163 -0.037214656682625136 0.029684649641602178 -0.014321448958271987 0.015613713741875751 0.0 \n",
      "         0.0 -0.010933811945437357 -0.0016609548063011383 0.022464727025412114 0.001308341654652631 -0.036051737009314286 -0.0037377552191601563 -0.019582520065357777 -0.0034299665844459253 0.0 \n",
      "         0.0 -0.018306856382126663 0.004151263979884004 0.04862712051772605 -0.03382051855190042 0.028678080755792788 -0.015751911773070292 0.029464422456675465 -0.02135249826983656 0.0 \n",
      "         0.0 -0.0034956722757745265 0.0031288834280170934 0.04033991978595436 0.0025229740494029347 0.018076831549847953 -0.0005054415211766241 0.02561436604916159 0.0019373898161007 0.0 \n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "    cores derivatives:\n",
      "      [0]:\n",
      "         -0.04753661562163756 -0.03960132735370978 -0.013875269763531567 \n",
      "         -0.10766078523150603 -0.10362236835078881 0.08326415033503004 \n",
      "         0.005273822388042228 -0.05044619061190922 0.17521065616117218 \n",
      "\n",
      "      [1]:\n",
      "         -0.006804903395345857 0.15613825710598217 0.0842740832559689 \n",
      "         0.04675760740427112 0.11072912055985161 -0.07449245065721914 \n",
      "         -0.1589531495213179 0.062257255914516904 -0.1069137725583194 \n",
      "\n",
      "    biases derivatives:\n",
      "      0.04889942844694227 0.034696791567142685 \n",
      "\n",
      "Max Pooling layer\n",
      "  derivatives values:\n",
      "    input derivatives:\n",
      "      [0]:\n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 -0.023015440027136347 0.0 \n",
      "         0.0 0.10795217014218977 0.0 0.16348016303194546 0.0 0.08447747519249937 0.0 0.0 \n",
      "         0.013940395056594793 0.0 -0.04029333091237762 0.0 -0.16161754089960548 0.0 -0.16007615972335948 0.0 \n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "         -0.07782731399026707 0.0 0.06908083000040594 0.0 -0.18156549350335613 0.0 -0.15903580296987074 0.0 \n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "         0.13308557579358088 0.0 0.13154066996183464 0.0 -0.011668255510624805 0.0 0.09799966123448797 0.0 \n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "      [1]:\n",
      "         0.0 0.0 0.16097839653943602 0.0 0.0 -0.07018751395828506 0.0 0.0 \n",
      "         0.18333635914295504 0.0 0.0 0.0 0.0 0.0 0.0 0.07560027388851313 \n",
      "         -0.1831523198376152 0.0 0.07821009784553343 0.0 0.067194733611315 0.0 -0.1136065173304685 0.0 \n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "         0.009057005098751965 0.0 -0.12264009255925033 0.0 0.11582958583008143 0.0 -0.006282468050038022 0.0 \n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "         0.18383496942626198 0.0 -0.2116431693892883 0.0 -0.1757217680966968 0.0 -0.11780436021760982 0.0 \n",
      "         0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "\n",
      "Dense layer\n",
      "  derivatives values:\n",
      "    input derivatives:\n",
      "      0.10795217014218977 0.16348016303194546 0.08447747519249937 -0.023015440027136347 0.013940395056594793 -0.04029333091237762 -0.16161754089960548 -0.16007615972335948 -0.07782731399026707 0.06908083000040594 -0.18156549350335613 -0.15903580296987074 0.13308557579358088 0.13154066996183464 -0.011668255510624805 0.09799966123448797 0.18333635914295504 0.16097839653943602 -0.07018751395828506 0.07560027388851313 -0.1831523198376152 0.07821009784553343 0.067194733611315 -0.1136065173304685 0.009057005098751965 -0.12264009255925033 0.11582958583008143 -0.006282468050038022 0.18383496942626198 -0.2116431693892883 -0.1757217680966968 -0.11780436021760982 \n",
      "    cores derivatives:\n",
      "      0.0016695064027370152 -0.1361301394220072 0.005423459951935412 0.010245122296545908 0.0025844341024134285 0.008160795678448879 0.011420125166198794 0.01307804456134961 0.013434522845458608 0.006323121442029335 \n",
      "      0.00230771089607021 -0.18816879379001 0.007496693396900547 0.014161539192991708 0.0035723892574099853 0.011280434191138434 0.015785712014830755 0.018077406522095458 0.018570156246865654 0.00874026971386514 \n",
      "      0.002048646500901179 -0.16704490221593654 0.006655112094865293 0.01257176007813706 0.0031713516474323857 0.010014088885083067 0.014013602717085247 0.01604803083433215 0.016485464310591898 0.007759084119563652 \n",
      "      0.0024017779671146535 -0.19583894316787803 0.007802274131283491 0.014738792832359756 0.003718007235228368 0.011740248029291628 0.01642917029901829 0.01881427901617996 0.019327114239287936 0.009096541192030723 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0015953655049107194 -0.13008475334776387 0.00518261020766235 0.009790147961520392 0.002469662296560096 0.007798383939515007 0.010912970277950051 0.012497263341223017 0.012837910826482671 0.006042318744891908 \n",
      "      0.0024762529599628813 -0.20191157106751434 0.008044209196923766 0.015195817380761364 0.003833296227818279 0.012104292874397902 0.016938610537572736 0.019397677362888034 0.019926414721870445 0.009378609247236493 \n",
      "      0.0020916998244339315 -0.1705554337871159 0.006794972580332616 0.012835961859060264 0.0032379991771321033 0.010224539935796582 0.014308105537055766 0.016385288171442365 0.016831914529426305 0.007922145125340134 \n",
      "      0.0020752233693538324 -0.16921195758147978 0.006741448140935269 0.012734852155597958 0.0032124932477591577 0.01014400057207004 0.01419539966243228 0.016256220194585645 0.016699328447801896 0.007859741874753728 \n",
      "      0.0011092470474005458 -0.09044706565277685 0.0036034344813034606 0.00680702490213282 0.0017171398040783418 0.005422164596624491 0.007587715806769586 0.008689264258985275 0.008926114194668095 0.004201184121502869 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "      0.0015814727759702234 -0.12895195198532441 0.005137479108489355 0.009704893597239547 0.0024481560343555656 0.007730474213554332 0.01081793817556312 0.01238843493070318 0.01272611599656715 0.0059897011495907235 \n",
      "\n",
      "    biases derivatives:\n",
      "      0.0025249475647215235 \n",
      "      -0.205882087936468 \n",
      "      0.008202395615586708 \n",
      "      0.015494637547079013 \n",
      "      0.00390867658990342 \n",
      "      0.012342319347028747 \n",
      "      0.01727170209107058 \n",
      "      0.019779125562120334 \n",
      "      0.020318260347025323 \n",
      "      0.009563036152671378 \n",
      "\n",
      "\n",
      "Softmax layer\n",
      "  derivatives values:\n",
      "    input derivatives:\n",
      "      0.13765833899291396 -0.9014585403679024 0.13116253962031982 0.07111285375614322 0.05567052566714709 0.06613599091300888 0.11719154296075138 0.11131745694430553 0.08178131066380928 0.12942798084950324 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_input = np.random.rand(2, 10, 10) * 2 - 1\n",
    "\n",
    "expected_output = np.zeros((10,))\n",
    "expected_output[1] = 1\n",
    "\n",
    "train_input = train_input.reshape(1,2,10,10)\n",
    "expected_output = expected_output.reshape(1,10)\n",
    "net.train(Data(train_input, expected_output))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}