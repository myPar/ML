{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from TPNN.tools.perceptron import*\n",
    "import numpy as np\n",
    "import numpy.random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "layers=3\n",
      "[0]\n",
      " size=2\n",
      " act_function=<function ident at 0x05D42538>\n",
      " activations=[[0. 0.]]\n",
      " biases=[[0. 0.]]\n",
      " weights:\n",
      "     empty\n",
      "--------------------------\n",
      "[1]\n",
      " size=5\n",
      " act_function=<function sigmoid at 0x0A0F1778>\n",
      " activations=[[0. 0. 0. 0. 0.]]\n",
      " biases=[[1 1 1 1 1]]\n",
      " weights:\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "\n",
      "--------------------------\n",
      "[2]\n",
      " size=1\n",
      " act_function=<function ident at 0x05D42538>\n",
      " activations=[[0.]]\n",
      " biases=[[0]]\n",
      " weights:\n",
      "     |1 |\n",
      "     |1 |\n",
      "     |1 |\n",
      "     |1 |\n",
      "     |1 |\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.insert_layer(0, 2, ident)\n",
    "net.insert_layer(1, 5, sigmoid)\n",
    "net.insert_layer(2, 1, ident)\n",
    "print(net.layers_count)\n",
    "net.init_weights(1, np.array([[1,1,1,1,1], [1,1,1,1,1]]))\n",
    "net.init_weights(2, np.array([[1,1,1,1,1]]).transpose())\n",
    "net.init_biases(2, np.array([[0]]))\n",
    "net.init_biases(1, np.array([[1,1,1,1,1]]))\n",
    "\n",
    "net.print_net_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.76287063]])"
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calc_output(np.array([1, 1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers=4\n",
      "[0]\n",
      " size=5\n",
      " act_function=<function ident at 0x05D42538>\n",
      " activations=[[0. 0. 0. 0. 0.]]\n",
      " biases=[[0. 0. 0. 0. 0.]]\n",
      " weights:\n",
      "     empty\n",
      "--------------------------\n",
      "[1]\n",
      " size=7\n",
      " act_function=<function sigmoid at 0x0A0F1778>\n",
      " activations=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " biases=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " weights:\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "\n",
      "--------------------------\n",
      "[2]\n",
      " size=7\n",
      " act_function=<function th at 0x0A0F17C0>\n",
      " activations=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " biases=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " weights:\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 -4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "\n",
      "--------------------------\n",
      "[3]\n",
      " size=5\n",
      " act_function=<function ident at 0x05D42538>\n",
      " activations=[[0. 0. 0. 0. 0.]]\n",
      " biases=[[1 1 1 1 1]]\n",
      " weights:\n",
      "     |1 1 0 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 0 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.insert_layer(0, 5, ident)\n",
    "net.insert_layer(1, 7, sigmoid)\n",
    "net.insert_layer(2, 7, th)\n",
    "net.insert_layer(3, 5, ident)\n",
    "\n",
    "net.init_weights(1, np.array([[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7]]))\n",
    "net.init_weights(2, np.array([[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,-4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7]]))\n",
    "net.init_weights(3, np.array([[1,1,0,1,1],[1,1,1,1,1],[1,1,1,0,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]]))\n",
    "net.init_biases(3, np.array([[1,1,1,1,1]]))\n",
    "\n",
    "net.print_net_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[7.99999833, 7.99999833, 7.        , 6.99999833, 7.99999833]])"
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calc_output(np.array([1,2,0,2,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fill activation derivatives array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [],
   "source": [
    "def calc_activations_derivatives(net: Net, target_vector):\n",
    "    assert target_vector.shape[0] == 1\n",
    "\n",
    "    last_layer = net.layers[net.layers_count - 1]\n",
    "    activation_der_array = []\n",
    "    last_layer_derivatives_array = []\n",
    "\n",
    "    for i in range(last_layer.neuron_count):\n",
    "        der = predict_error_der(last_layer.activations[0], target_vector, i)\n",
    "        last_layer_derivatives_array.append(der)\n",
    "\n",
    "    activation_der_array.insert(0, last_layer_derivatives_array)\n",
    "\n",
    "    # cal derivatives on each layer, except last and first layers\n",
    "    for i in range(net.layers_count - 2, 0, -1):\n",
    "        cur_layer = net.layers[i]\n",
    "        layer_derivatives_array = []\n",
    "\n",
    "        for j in range(cur_layer.neuron_count):\n",
    "            next_layer_der_array = activation_der_array[0]\n",
    "            layer_derivatives_array.append(net.der_cost_act(i, j, next_layer_der_array))\n",
    "\n",
    "        # add derivatives array of the current layer\n",
    "        activation_der_array.insert(0, layer_derivatives_array)\n",
    "\n",
    "    return activation_der_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Net training functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [],
   "source": [
    "def get_weight_gradient_matrix(net: Net, layer_idx, activation_der_array):\n",
    "    assert 0 < layer_idx < net.layers_count\n",
    "    prev_layer_neuron_count = net.layers[layer_idx - 1].neuron_count\n",
    "    cur_layer_neuron_count = net.layers[layer_idx].neuron_count\n",
    "\n",
    "    gradient_matrix = np.zeros((prev_layer_neuron_count, cur_layer_neuron_count))\n",
    "\n",
    "    for i in range(prev_layer_neuron_count):\n",
    "        for j in range(cur_layer_neuron_count):\n",
    "            gradient_matrix[i][j] = net.der_cost_weigh(layer_idx, i, j, activation_der_array[layer_idx - 1][j])\n",
    "    return gradient_matrix\n",
    "\n",
    "def get_bias_gradient_matrix(net: Net, layer_idx, activation_der_array):\n",
    "    assert 0 < layer_idx < net.layers_count\n",
    "    cur_layer_neuron_count = net.layers[layer_idx].neuron_count\n",
    "    gradient_vector = [np.zeros(cur_layer_neuron_count)]\n",
    "\n",
    "    for j in range(cur_layer_neuron_count):\n",
    "        gradient_vector[0][j] = net.der_cost_bias(layer_idx, j, activation_der_array[layer_idx - 1][j])\n",
    "\n",
    "    return gradient_vector\n",
    "\n",
    "def step(net: Net, weight_grad_matrices, biases_grad_matrices):\n",
    "    learning_rate = 0.001\n",
    "    l = lambda x: x * learning_rate\n",
    "    f = np.vectorize(l)\n",
    "\n",
    "    for i in range(net.layers_count - 1):\n",
    "        idx = i + 1\n",
    "        cur_layer = net.layers[idx]\n",
    "        cur_layer.weights -= f(weight_grad_matrices[idx - 1])\n",
    "        cur_layer.biases -= f(biases_grad_matrices[idx - 1])\n",
    "\n",
    "def training_iteration(training_data_item, target_vector, net: Net):\n",
    "    net.calc_output(training_data_item)\n",
    "    act_der_array = calc_activations_derivatives(net, target_vector)\n",
    "\n",
    "    weight_grad_matrices = []\n",
    "    biases_grad_matrices = []\n",
    "\n",
    "    for i in range(net.layers_count - 1):\n",
    "        idx = i + 1\n",
    "        weight_grad_matrices.append(get_weight_gradient_matrix(net, idx, act_der_array))\n",
    "        biases_grad_matrices.append(get_bias_gradient_matrix(net, idx, act_der_array))\n",
    "    # change net parameters\n",
    "    step(net, weight_grad_matrices, biases_grad_matrices)\n",
    "\n",
    "def calc_metric(net: Net, val_input_vectors, val_target_vectors):\n",
    "    predict_errors = []\n",
    "\n",
    "    idx = 0\n",
    "    for target_vector in val_target_vectors:\n",
    "        input_vector = val_input_vectors[idx]\n",
    "        output = net.calc_output(input_vector)\n",
    "        predict_errors = np.append(predict_errors, predict_error(output, target_vector))\n",
    "        idx += 1\n",
    "\n",
    "    return np.mean(predict_errors)\n",
    "\n",
    "# net training on all training data items (returns metric on validation)\n",
    "def training(net: Net, training_data, target_vectors, val_input_vectors, val_target_vectors):\n",
    "    for training_item, target_vector in zip(training_data, target_vectors):\n",
    "        training_iteration(training_item, target_vector, net)\n",
    "    return calc_metric(net, val_input_vectors, val_target_vectors)\n",
    "\n",
    "# init weights and biases with start values\n",
    "def init_net_parameters(net: Net):\n",
    "    for i in range(net.layers_count - 1):\n",
    "        idx = i + 1\n",
    "        w_shape = net.layers[idx].weights.shape\n",
    "        b_shape = net.layers[idx].biases.shape\n",
    "\n",
    "        interval = (-0.5, 0.5)\n",
    "        delta = interval[1] - interval[0]\n",
    "\n",
    "        net.layers[idx].weights = rand.rand(w_shape[0], w_shape[1]) * delta + interval[0]\n",
    "        net.layers[idx].biases = rand.rand(b_shape[0], b_shape[1]) * delta + interval[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## generation of training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [],
   "source": [
    "periods_count = 50\n",
    "epsilon = 0.1\n",
    "st_points_count = 20\n",
    "\n",
    "dst_dir = \"../data_sets/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [],
   "source": [
    "training_data_file = open(dst_dir + \"cos_values_data\", \"w\")\n",
    "\n",
    "# 1 - write extremum points\n",
    "training_data_file.write(str(0) + \" \" + str(1) + \"\\n\")\n",
    "\n",
    "for i in range(periods_count - 1):\n",
    "    x = (np.pi / 2) * (i + 1)\n",
    "\n",
    "    val1 = np.cos(x)\n",
    "    val2 = np.cos(-x)\n",
    "    training_data_file.write(str(x) + \" \" + str(val1) + \"\\n\" + str(-x) + \" \" + str(val2) + \"\\n\")\n",
    "\n",
    "# write other points\n",
    "st_points = np.linspace(epsilon, np.pi / 2 - epsilon, st_points_count)\n",
    "\n",
    "for st_point in st_points:\n",
    "    for i in range(periods_count):\n",
    "        x = st_point + (np.pi / 2) * i\n",
    "        val1 = np.cos(x)\n",
    "        val2 = np.cos(-x)\n",
    "        training_data_file.write(str(x) + \" \" + str(val1) + \"\\n\" + str(-x) + \" \" + str(val2) + \"\\n\")\n",
    "\n",
    "training_data_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sorting: ['0 1\\n', '1.5707963267948966 6.123233995736766e-17\\n', '-1.5707963267948966 6.123233995736766e-17\\n', '3.141592653589793 -1.0\\n', '-3.141592653589793 -1.0\\n']\n",
      "after sorting: ['-78.43981633974482 -0.9950041652780249\\n', '-78.36766916465035 -0.9852192311124913\\n', '-78.29552198955588 -0.9703082432473036\\n', '-78.22337481446142 -0.9503487829172798\\n', '-78.15122763936695 -0.9254446983444491\\n']\n",
      "-------------------------\n",
      "first 5 training items: \n",
      "[[-78.43981634]\n",
      " [-78.36766916]\n",
      " [-78.29552199]\n",
      " [-78.22337481]\n",
      " [-78.15122764]]\n",
      "first 5 training target vectors: \n",
      "[[-0.99500417]\n",
      " [-0.98521923]\n",
      " [-0.97030824]\n",
      " [-0.95034878]\n",
      " [-0.9254447 ]]\n"
     ]
    }
   ],
   "source": [
    "training_data_file = open(dst_dir + \"cos_values_data\", \"r\")\n",
    "training_data = np.array([])\n",
    "target_vectors = np.array([])\n",
    "lines = []\n",
    "items_count = 0\n",
    "\n",
    "# read lines and shuffle it\n",
    "for line in training_data_file:\n",
    "    lines.append(line)\n",
    "\n",
    "print(\"before sorting: \" + str(lines[0:5]))\n",
    "lines = sorted(lines, key=lambda l: float(l.split()[0]))\n",
    "print(\"after sorting: \" + str(lines[0:5]))\n",
    "print(\"-------------------------\")\n",
    "\n",
    "# get training data items and target vectors:\n",
    "for line in lines:\n",
    "    arg, value = line.split()\n",
    "    arg = float(arg)\n",
    "    value = float(value)\n",
    "\n",
    "    training_data = np.append(training_data, arg)\n",
    "    target_vectors = np.append(target_vectors, value)\n",
    "    items_count += 1\n",
    "\n",
    "# reshape data to array of 1-d vectors\n",
    "training_data = training_data.reshape((items_count, 1))\n",
    "target_vectors = target_vectors.reshape((items_count, 1))\n",
    "\n",
    "print(\"first 5 training items: \\n\" + str(training_data[0:5]))\n",
    "print(\"first 5 training target vectors: \\n\" + str(target_vectors[0:5]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split training data on batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches' count: 21\n",
      "---------\n",
      "training data batch 1:\n",
      "[[-71.00227623]\n",
      " [-70.93012906]\n",
      " [-70.85798188]\n",
      " [-70.78583471]\n",
      " [-70.68583471]\n",
      " [-70.58583471]\n",
      " [-70.51368753]\n",
      " [-70.44154036]\n",
      " [-70.36939318]\n",
      " [-70.29724601]\n",
      " [-70.22509883]\n",
      " [-70.15295166]\n",
      " [-70.08080448]\n",
      " [-70.00865731]\n",
      " [-69.93651013]\n",
      " [-69.86436295]\n",
      " [-69.79221578]\n",
      " [-69.7200686 ]\n",
      " [-69.64792143]\n",
      " [-69.57577425]\n",
      " [-69.50362708]\n",
      " [-69.4314799 ]\n",
      " [-69.35933273]\n",
      " [-69.28718555]\n",
      " [-69.21503838]\n",
      " [-69.11503838]\n",
      " [-69.01503838]\n",
      " [-68.9428912 ]\n",
      " [-68.87074403]\n",
      " [-68.79859685]\n",
      " [-68.72644968]\n",
      " [-68.6543025 ]\n",
      " [-68.58215533]\n",
      " [-68.51000815]\n",
      " [-68.43786098]\n",
      " [-68.3657138 ]\n",
      " [-68.29356663]\n",
      " [-68.22141945]\n",
      " [-68.14927228]\n",
      " [-68.0771251 ]\n",
      " [-68.00497793]\n",
      " [-67.93283075]\n",
      " [-67.86068358]\n",
      " [-67.7885364 ]\n",
      " [-67.71638923]\n",
      " [-67.64424205]\n",
      " [-67.54424205]\n",
      " [-67.44424205]\n",
      " [-67.37209488]\n",
      " [-67.2999477 ]\n",
      " [-67.22780053]\n",
      " [-67.15565335]\n",
      " [-67.08350618]\n",
      " [-67.011359  ]\n",
      " [-66.93921183]\n",
      " [-66.86706465]\n",
      " [-66.79491748]\n",
      " [-66.7227703 ]\n",
      " [-66.65062313]\n",
      " [-66.57847595]\n",
      " [-66.50632878]\n",
      " [-66.4341816 ]\n",
      " [-66.36203443]\n",
      " [-66.28988725]\n",
      " [-66.21774008]\n",
      " [-66.1455929 ]\n",
      " [-66.07344573]\n",
      " [-65.97344573]\n",
      " [-65.87344573]\n",
      " [-65.80129855]\n",
      " [-65.72915138]\n",
      " [-65.6570042 ]\n",
      " [-65.58485703]\n",
      " [-65.51270985]\n",
      " [-65.44056267]\n",
      " [-65.3684155 ]\n",
      " [-65.29626832]\n",
      " [-65.22412115]\n",
      " [-65.15197397]\n",
      " [-65.0798268 ]\n",
      " [-65.00767962]\n",
      " [-64.93553245]\n",
      " [-64.86338527]\n",
      " [-64.7912381 ]\n",
      " [-64.71909092]\n",
      " [-64.64694375]\n",
      " [-64.57479657]\n",
      " [-64.5026494 ]\n",
      " [-64.4026494 ]\n",
      " [-64.3026494 ]\n",
      " [-64.23050222]\n",
      " [-64.15835505]\n",
      " [-64.08620787]\n",
      " [-64.0140607 ]\n",
      " [-63.94191352]\n",
      " [-63.86976635]\n",
      " [-63.79761917]\n",
      " [-63.725472  ]\n",
      " [-63.65332482]\n",
      " [-63.58117765]]\n",
      "size=100\n",
      "---------\n",
      "target vectors batch 1:\n",
      "[[-3.11186746e-01]\n",
      " [-2.41871687e-01]\n",
      " [-1.71298181e-01]\n",
      " [-9.98334166e-02]\n",
      " [ 9.79098459e-16]\n",
      " [ 9.98334166e-02]\n",
      " [ 1.71298181e-01]\n",
      " [ 2.41871687e-01]\n",
      " [ 3.11186746e-01]\n",
      " [ 3.78882713e-01]\n",
      " [ 4.44607370e-01]\n",
      " [ 5.08018753e-01]\n",
      " [ 5.68786937e-01]\n",
      " [ 6.26595746e-01]\n",
      " [ 6.81144404e-01]\n",
      " [ 7.32149097e-01]\n",
      " [ 7.79344450e-01]\n",
      " [ 8.22484906e-01]\n",
      " [ 8.61346009e-01]\n",
      " [ 8.95725564e-01]\n",
      " [ 9.25444698e-01]\n",
      " [ 9.50348783e-01]\n",
      " [ 9.70308243e-01]\n",
      " [ 9.85219231e-01]\n",
      " [ 9.95004165e-01]\n",
      " [ 1.00000000e+00]\n",
      " [ 9.95004165e-01]\n",
      " [ 9.85219231e-01]\n",
      " [ 9.70308243e-01]\n",
      " [ 9.50348783e-01]\n",
      " [ 9.25444698e-01]\n",
      " [ 8.95725564e-01]\n",
      " [ 8.61346009e-01]\n",
      " [ 8.22484906e-01]\n",
      " [ 7.79344450e-01]\n",
      " [ 7.32149097e-01]\n",
      " [ 6.81144404e-01]\n",
      " [ 6.26595746e-01]\n",
      " [ 5.68786937e-01]\n",
      " [ 5.08018753e-01]\n",
      " [ 4.44607370e-01]\n",
      " [ 3.78882713e-01]\n",
      " [ 3.11186746e-01]\n",
      " [ 2.41871687e-01]\n",
      " [ 1.71298181e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-4.40934746e-15]\n",
      " [-9.98334166e-02]\n",
      " [-1.71298181e-01]\n",
      " [-2.41871687e-01]\n",
      " [-3.11186746e-01]\n",
      " [-3.78882713e-01]\n",
      " [-4.44607370e-01]\n",
      " [-5.08018753e-01]\n",
      " [-5.68786937e-01]\n",
      " [-6.26595746e-01]\n",
      " [-6.81144404e-01]\n",
      " [-7.32149097e-01]\n",
      " [-7.79344450e-01]\n",
      " [-8.22484906e-01]\n",
      " [-8.61346009e-01]\n",
      " [-8.95725564e-01]\n",
      " [-9.25444698e-01]\n",
      " [-9.50348783e-01]\n",
      " [-9.70308243e-01]\n",
      " [-9.85219231e-01]\n",
      " [-9.95004165e-01]\n",
      " [-1.00000000e+00]\n",
      " [-9.95004165e-01]\n",
      " [-9.85219231e-01]\n",
      " [-9.70308243e-01]\n",
      " [-9.50348783e-01]\n",
      " [-9.25444698e-01]\n",
      " [-8.95725564e-01]\n",
      " [-8.61346009e-01]\n",
      " [-8.22484906e-01]\n",
      " [-7.79344450e-01]\n",
      " [-7.32149097e-01]\n",
      " [-6.81144404e-01]\n",
      " [-6.26595746e-01]\n",
      " [-5.68786937e-01]\n",
      " [-5.08018753e-01]\n",
      " [-4.44607370e-01]\n",
      " [-3.78882713e-01]\n",
      " [-3.11186746e-01]\n",
      " [-2.41871687e-01]\n",
      " [-1.71298181e-01]\n",
      " [-9.98334166e-02]\n",
      " [ 7.83959646e-15]\n",
      " [ 9.98334166e-02]\n",
      " [ 1.71298181e-01]\n",
      " [ 2.41871687e-01]\n",
      " [ 3.11186746e-01]\n",
      " [ 3.78882713e-01]\n",
      " [ 4.44607370e-01]\n",
      " [ 5.08018753e-01]\n",
      " [ 5.68786937e-01]\n",
      " [ 6.26595746e-01]\n",
      " [ 6.81144404e-01]\n",
      " [ 7.32149097e-01]]\n",
      "size=100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "data_size = len(training_data)\n",
    "batch_count = data_size // batch_size\n",
    "rem = data_size % batch_size\n",
    "training_data_batches = []\n",
    "target_vectors_batches = []\n",
    "\n",
    "if data_size % batch_size != 0:\n",
    "    batch_count += 1\n",
    "\n",
    "for i in range(batch_count):\n",
    "    pos = i * batch_size\n",
    "    tr_data_batch = []\n",
    "    t_vectors_batch = []\n",
    "\n",
    "    if i == batch_count - 1:\n",
    "        tr_data_batch = training_data[pos:]\n",
    "        t_vectors_batch = target_vectors[pos:]\n",
    "    else:\n",
    "        tr_data_batch = training_data[pos:pos + batch_size]\n",
    "        t_vectors_batch = target_vectors[pos:pos + batch_size]\n",
    "    training_data_batches.append(tr_data_batch)\n",
    "    target_vectors_batches.append(t_vectors_batch)\n",
    "\n",
    "print(\"batches' count: \" + str(batch_count))\n",
    "print(\"---------\")\n",
    "idx = 1\n",
    "print(\"training data batch \" + str(idx) + \":\\n\" + str(training_data_batches[idx]))\n",
    "print(\"size=\" + str(len(training_data_batches[idx])))\n",
    "\n",
    "print(\"---------\")\n",
    "print(\"target vectors batch \" + str(idx) + \":\\n\" + str(target_vectors_batches[idx]))\n",
    "print(\"size=\" + str(len(target_vectors_batches[idx])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create net and train it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers=4\n",
      "[0]\n",
      " size=1\n",
      " act_function=<function ident at 0x05D42538>\n",
      " activations=[[0.]]\n",
      " biases=[[0.]]\n",
      " weights:\n",
      "     empty\n",
      "--------------------------\n",
      "[1]\n",
      " size=10\n",
      " act_function=<function th at 0x0A0F17C0>\n",
      " activations=[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      " biases=[[-0.10189921  0.44463151  0.4888648   0.48308052 -0.28123689  0.34229224\n",
      "   0.43164378  0.17847609  0.22655201  0.03204047]]\n",
      " weights:\n",
      "     |0.49348466741918806 0.4898229810878617 0.19802746092523638 0.41144345146240036 -0.23747814910667042 -0.25468440442996276 0.48971826363897863 0.47331915899125243 -0.326662993488393 0.2069944502949601 |\n",
      "\n",
      "--------------------------\n",
      "[2]\n",
      " size=10\n",
      " act_function=<function th at 0x0A0F17C0>\n",
      " activations=[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      " biases=[[-0.19989819 -0.25108238 -0.21081007  0.4418575  -0.13792872 -0.47424723\n",
      "  -0.33216886 -0.00278209 -0.1831021   0.3762984 ]]\n",
      " weights:\n",
      "     |-0.4681985088187054 -0.48348167813462506 0.3897024452549418 -0.32450654653299904 -0.15626816396342158 0.24179335833046256 0.21679381439054723 -0.19027882613342273 -0.014757440015947476 -0.24339439459183398 |\n",
      "     |-0.33105954636682855 -0.08186300992527995 0.3824663847790296 -0.104012343570701 0.16980850636176492 -0.19747648931454653 0.46086721790465557 0.4659030924691693 0.1448612842528505 0.3075085729722863 |\n",
      "     |0.43610644493916007 0.32729924675751343 -0.3544392054697948 0.15451184689272945 -0.3737493965079296 -0.13755028635102717 0.16444733548336177 0.47332605632641556 -0.47484956015464297 -0.2546944843261877 |\n",
      "     |-0.40720659764097 0.27739583576807936 0.39330881741404955 0.36678826946650267 0.42719066405712414 0.43041931974430125 0.035989515174938425 -0.10606534399474632 0.1593167120681379 0.23800140900967126 |\n",
      "     |-0.10140430363139785 0.0639629016183152 0.06903546227456092 0.3256923326293163 -0.0857487422036809 -0.421665293365169 -0.15971812337985336 -0.45424673270330307 -0.37375700342055374 -0.2523862144596748 |\n",
      "     |-0.48021383621563196 0.4317700605845153 -0.01663024861174911 0.319138821674641 0.04980759136104551 -0.3644650491957765 0.21548796989265262 -0.04919335203786179 -0.49135863824553994 -0.1406281353231269 |\n",
      "     |0.40241861339669227 0.3892646021957261 0.2353989173338097 0.4928655029812332 -0.34862401984932756 0.43408797420418443 0.396472028286632 -0.4629844799213422 0.3369516926094259 0.13493846847978053 |\n",
      "     |-0.4031992418369047 0.47768216798218976 -0.39525033206619686 0.39279761143557923 0.04848611955849946 0.25623060608307324 -0.15488084588370066 0.19672207310460577 0.37229024797256716 0.2914591267866323 |\n",
      "     |-0.1732943362836623 0.4641394479356653 0.3203981104094793 -0.19969614760631316 -0.034607063972833085 0.004282353875297851 -0.4737216162600656 -0.10632315135837067 0.1589361897109267 0.04029058724766266 |\n",
      "     |-0.4712748539255087 -0.02557555336722539 0.42574360794557353 -0.15576125446952782 -0.1934380219991948 -0.200837340557946 0.12923634603579703 0.47066264765318544 -0.05184475818512335 0.1439422101620388 |\n",
      "\n",
      "--------------------------\n",
      "[3]\n",
      " size=1\n",
      " act_function=<function ident at 0x05D42538>\n",
      " activations=[[0.]]\n",
      " biases=[[0.00321232]]\n",
      " weights:\n",
      "     |-0.33866418680863364 |\n",
      "     |-0.4505966711731688 |\n",
      "     |0.2534756325053026 |\n",
      "     |-0.367185241062988 |\n",
      "     |-0.2872903138460766 |\n",
      "     |-0.45381211644697417 |\n",
      "     |0.2719284378125859 |\n",
      "     |0.1323850219481083 |\n",
      "     |0.18971974877896935 |\n",
      "     |0.4170261813190548 |\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# net parameters\n",
    "net = Net()\n",
    "hidden_layers_size = 10\n",
    "hidden_layers_count = 2\n",
    "activation = th\n",
    "\n",
    "net.insert_layer(0, 1, ident)\n",
    "\n",
    "for i in range(hidden_layers_count):\n",
    "    net.insert_layer(i + 1, hidden_layers_size, activation)\n",
    "net.insert_layer(hidden_layers_count + 1, 1, ident)\n",
    "#print(net.layers_count)\n",
    "\n",
    "for i in range(hidden_layers_count):\n",
    "    idx = i + 1\n",
    "    cur_layer = net.layers[idx]\n",
    "\n",
    "    if i == 0:\n",
    "        cur_layer.weights = np.zeros((1, hidden_layers_size))\n",
    "    else:\n",
    "        cur_layer.weights = np.zeros((hidden_layers_size, hidden_layers_size))\n",
    "    cur_layer.biases = np.zeros((1, hidden_layers_size))\n",
    "\n",
    "net.init_weights(net.layers_count - 1, np.zeros((hidden_layers_size, 1)))\n",
    "net.init_biases(net.layers_count - 1, np.zeros((1, 1)))\n",
    "\n",
    "# init all net parameters with values from standart normal destribution\n",
    "init_net_parameters(net)\n",
    "\n",
    "net.print_net_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 0.7252484417831693\n",
      "epoch 1: 0.6889946983681182\n",
      "epoch 2: 0.6679087497316731\n",
      "epoch 3: 0.6646659887466483\n",
      "epoch 4: 0.6724375635000721\n",
      "epoch 5: 0.6894869498156289\n",
      "epoch 6: 0.6865625038684654\n",
      "epoch 7: 0.6695086322641455\n",
      "epoch 8: 0.6640936809466762\n",
      "epoch 9: 0.6665173301905517\n",
      "epoch 10: 0.6539413962192094\n",
      "epoch 11: 0.6521812541133866\n",
      "epoch 12: 0.6510793627563596\n",
      "epoch 13: 0.6489990011481175\n",
      "epoch 14: 0.6496087414804866\n",
      "epoch 15: 0.6586528493880314\n",
      "epoch 16: 0.6661491590257815\n",
      "epoch 17: 0.656799879503033\n",
      "epoch 18: 0.6493111947807878\n",
      "epoch 19: 0.6491579738592658\n",
      "epoch 20: 0.6549480565923463\n"
     ]
    }
   ],
   "source": [
    "min_cost = 0.05\n",
    "saved_nets = []\n",
    "\n",
    "for i in range(batch_count):\n",
    "    training_batch = training_data_batches[i]\n",
    "    target_vectors_batch = target_vectors_batches[i]\n",
    "\n",
    "    cost = training(net, training_batch, target_vectors_batch, training_data, target_vectors)\n",
    "    saved_nets.append((copy.deepcopy(net), cost))\n",
    "\n",
    "    print(\"epoch \" + str(i) + \": \" + str(cost))\n",
    "\n",
    "    if cost <= min_cost:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get best net config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric of the best net - 0.6489990011481175\n",
      "layers=4\n",
      "[0]\n",
      " size=1\n",
      " act_function=<function ident at 0x05D42538>\n",
      " activations=[[78.43981634]]\n",
      " biases=[[0.]]\n",
      " weights:\n",
      "     empty\n",
      "--------------------------\n",
      "[1]\n",
      " size=10\n",
      " act_function=<function th at 0x0A0F17C0>\n",
      " activations=[[ 1.  1.  1.  1. -1. -1.  1.  1. -1.  1.]]\n",
      " biases=[[-0.09944205  0.45015797  0.49127605  0.48249391 -0.27994141  0.34550836\n",
      "   0.42983199  0.17641664  0.22702225  0.03080921]]\n",
      " weights:\n",
      "     |0.4879690693040836 0.49130288040732056 0.20318483350741942 0.4095923334863581 -0.24217641673475598 -0.25149081512288535 0.4859781075210512 0.4753165107317751 -0.32301203778167803 0.18856866056982396 |\n",
      "\n",
      "--------------------------\n",
      "[2]\n",
      " size=10\n",
      " act_function=<function th at 0x0A0F17C0>\n",
      " activations=[[-0.43519084  0.02182684  0.35848235  0.77398232 -0.26804105  0.83995634\n",
      "   0.86385991  0.8934809   0.7405313   0.82263188]]\n",
      " biases=[[-0.21068617 -0.257047   -0.20946733  0.42769027 -0.144449   -0.47292564\n",
      "  -0.33067507 -0.00205806 -0.18212399  0.3889077 ]]\n",
      " weights:\n",
      "     |-0.4437704584619286 -0.44598735370417625 0.3764291773349311 -0.30182991535237186 -0.1323392882102004 0.25312889750994083 0.21277870673148366 -0.19220458256089384 -0.020057571358359533 -0.2636014133202044 |\n",
      "     |-0.30843148813060545 -0.04583950079075661 0.37058958893350163 -0.08212739239886895 0.19231430509611294 -0.18945250809691128 0.4586575921232893 0.4645596870935991 0.14060069143089154 0.2889680260097687 |\n",
      "     |0.4592644999962663 0.3639087050332215 -0.36583756003311674 0.1780837452011388 -0.3511744135976792 -0.13107315022288352 0.16268807625961912 0.4717573156480465 -0.478704395252708 -0.274717647204668 |\n",
      "     |-0.3843623934484964 0.31378241258894946 0.3815208516589991 0.3892022989722657 0.44984106657496603 0.4380095750012226 0.03395762209762408 -0.10744038823578375 0.15516834233108437 0.21905275426611825 |\n",
      "     |-0.12468578595113838 0.027754719271661468 0.0807197947183722 0.30254553020523295 -0.10836525977886202 -0.4292203528327124 -0.15738536936137923 -0.4526401597056009 -0.36959359915907614 -0.2325297218955262 |\n",
      "     |-0.5031055949457727 0.39878947152630945 -0.005195486715733778 0.29709419323906083 0.02844013386197191 -0.3734467495413528 0.21912929956882451 -0.047421330679443145 -0.4868240653213802 -0.12112655834737078 |\n",
      "     |0.4250952401042319 0.42533146808855926 0.22349587432250287 0.5147907910642778 -0.32608189845028107 0.4421728170367936 0.39422785516473713 -0.4643426884960117 0.33267208797663905 0.11634354195694363 |\n",
      "     |-0.3797215504429072 0.514396390427887 -0.40778721159731696 0.4150538827448702 0.07166197268559696 0.26582017347254133 -0.15794580390096122 0.1951030230150924 0.36753790995560304 0.27213202312717133 |\n",
      "     |-0.19703980852950229 0.42878892569405974 0.33276045289961564 -0.2221854723001837 -0.05731762247855139 -0.005846322051753924 -0.46990284739913146 -0.10446337492231325 0.16384603781140916 0.06025158092222653 |\n",
      "     |-0.44850147787209105 0.008618306927203997 0.41448473648040834 -0.1332249510620381 -0.1717675309402882 -0.193168367768705 0.1265123019525478 0.4690247795883934 -0.056009896398263856 0.12441505888902867 |\n",
      "\n",
      "--------------------------\n",
      "[3]\n",
      " size=1\n",
      " act_function=<function ident at 0x05D42538>\n",
      " activations=[[0.14944976]]\n",
      " biases=[[0.02381607]]\n",
      " weights:\n",
      "     |-0.3108096924042658 |\n",
      "     |-0.46370733244400086 |\n",
      "     |0.20418311672978623 |\n",
      "     |-0.39126436534135056 |\n",
      "     |-0.2696758607657647 |\n",
      "     |-0.5357089439470467 |\n",
      "     |0.19182951814944518 |\n",
      "     |0.05755590161542778 |\n",
      "     |0.11882121113615988 |\n",
      "     |0.3679498071032942 |\n",
      "\n",
      "--------------------------\n",
      "[[-0.04651063]]\n",
      "[[-0.0417955]]\n",
      "[[0.14937077]]\n"
     ]
    }
   ],
   "source": [
    "min = 10000\n",
    "result = 0\n",
    "\n",
    "for item in saved_nets:\n",
    "    if item[1] < min:\n",
    "        result = item\n",
    "        min = item[1]\n",
    "\n",
    "result_net = result[0]\n",
    "\n",
    "# check net cost function\n",
    "print(\"metric of the best net - \" + str(calc_metric(result_net, training_data, target_vectors)))\n",
    "\n",
    "result_net.print_net_config()\n",
    "\n",
    "print(result_net.calc_output([np.pi/2]))\n",
    "print(result_net.calc_output([np.pi/4]))\n",
    "print(result_net.calc_output([23]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}