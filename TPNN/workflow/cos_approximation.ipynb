{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from TPNN.tools.perceptron import*\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import numpy.random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "layers=3\n",
      "[0]\n",
      " size=2\n",
      " act_function=<function ident at 0x068C1220>\n",
      " activations=[[0. 0.]]\n",
      " biases=[[0. 0.]]\n",
      " weights:\n",
      "     empty\n",
      "--------------------------\n",
      "[1]\n",
      " size=5\n",
      " act_function=<function sigmoid at 0x0AC6E7C0>\n",
      " activations=[[0. 0. 0. 0. 0.]]\n",
      " biases=[[1 1 1 1 1]]\n",
      " weights:\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "\n",
      "--------------------------\n",
      "[2]\n",
      " size=1\n",
      " act_function=<function ident at 0x068C1220>\n",
      " activations=[[0.]]\n",
      " biases=[[0]]\n",
      " weights:\n",
      "     |1 |\n",
      "     |1 |\n",
      "     |1 |\n",
      "     |1 |\n",
      "     |1 |\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.insert_layer(0, 2, ident)\n",
    "net.insert_layer(1, 5, sigmoid)\n",
    "net.insert_layer(2, 1, ident)\n",
    "print(net.layers_count)\n",
    "net.init_weights(1, np.array([[1,1,1,1,1], [1,1,1,1,1]]))\n",
    "net.init_weights(2, np.array([[1,1,1,1,1]]).transpose())\n",
    "net.init_biases(2, np.array([[0]]))\n",
    "net.init_biases(1, np.array([[1,1,1,1,1]]))\n",
    "\n",
    "net.print_net_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.76287063]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calc_output(np.array([1, 1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers=4\n",
      "[0]\n",
      " size=5\n",
      " act_function=<function ident at 0x068C1220>\n",
      " activations=[[0. 0. 0. 0. 0.]]\n",
      " biases=[[0. 0. 0. 0. 0.]]\n",
      " weights:\n",
      "     empty\n",
      "--------------------------\n",
      "[1]\n",
      " size=7\n",
      " act_function=<function sigmoid at 0x0AC6E7C0>\n",
      " activations=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " biases=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " weights:\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "\n",
      "--------------------------\n",
      "[2]\n",
      " size=7\n",
      " act_function=<function th at 0x0AC6E808>\n",
      " activations=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " biases=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " weights:\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 -4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "\n",
      "--------------------------\n",
      "[3]\n",
      " size=5\n",
      " act_function=<function ident at 0x068C1220>\n",
      " activations=[[0. 0. 0. 0. 0.]]\n",
      " biases=[[1 1 1 1 1]]\n",
      " weights:\n",
      "     |1 1 0 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 0 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.insert_layer(0, 5, ident)\n",
    "net.insert_layer(1, 7, sigmoid)\n",
    "net.insert_layer(2, 7, th)\n",
    "net.insert_layer(3, 5, ident)\n",
    "\n",
    "net.init_weights(1, np.array([[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7]]))\n",
    "net.init_weights(2, np.array([[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,-4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7]]))\n",
    "net.init_weights(3, np.array([[1,1,0,1,1],[1,1,1,1,1],[1,1,1,0,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]]))\n",
    "net.init_biases(3, np.array([[1,1,1,1,1]]))\n",
    "\n",
    "net.print_net_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[7.99999833, 7.99999833, 7.        , 6.99999833, 7.99999833]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calc_output(np.array([1,2,0,2,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fill activation derivatives array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([list([1, 1]), list([1]), list([1, 1, 1])], dtype=object)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_activations_derivatives(net: Net, target_vector):\n",
    "    last_layer = net.layers[net.layers_count - 1]\n",
    "    activation_der_array = []\n",
    "    last_layer_derivatives_array = []\n",
    "\n",
    "    for i in range(last_layer.neuron_count):\n",
    "        der = predict_error_der(last_layer.activations, target_vector, i)\n",
    "        last_layer_derivatives_array.append(der)\n",
    "\n",
    "    activation_der_array.insert(0, last_layer_derivatives_array)\n",
    "\n",
    "    # cal derivatives on each layer, except last and first layers\n",
    "    cur_iteration = 0\n",
    "    for i in range(net.layers_count - 2, 0, -1):\n",
    "        cur_layer = net.layers[i]\n",
    "        layer_derivatives_array = []\n",
    "\n",
    "        for j in range(cur_layer.neuron_count):\n",
    "            next_layer_der_array = activation_der_array[0]\n",
    "            layer_derivatives_array.append(net.der_cost_act(i, j, next_layer_der_array))\n",
    "\n",
    "        # add derivatives array of the current layer\n",
    "        activation_der_array.insert(0, layer_derivatives_array)\n",
    "        cur_iteration += 1\n",
    "\n",
    "    return activation_der_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Net training functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_weight_gradient_matrix(net: Net, layer_idx, activation_der_array):\n",
    "    assert 0 < layer_idx < net.layers_count\n",
    "    prev_layer_neuron_count = net.layers[layer_idx - 1]\n",
    "    cur_layer_neuron_count = net.layers[layer_idx]\n",
    "\n",
    "    gradient_matrix = np.zeros((prev_layer_neuron_count, cur_layer_neuron_count))\n",
    "\n",
    "    for i in range(prev_layer_neuron_count):\n",
    "        for j in range(len(cur_layer_neuron_count)):\n",
    "            gradient_matrix[i][j] = net.der_cost_weigh(layer_idx, i, j, activation_der_array[layer_idx - 1][j])\n",
    "    return gradient_matrix\n",
    "\n",
    "def get_bias_gradient_matrix(net: Net, layer_idx, activation_der_array):\n",
    "    assert 0 < layer_idx < net.layers_count\n",
    "    cur_layer_neuron_count = net.layers[layer_idx]\n",
    "    gradient_vector = np.zeroes(cur_layer_neuron_count)\n",
    "\n",
    "    for j in range(cur_layer_neuron_count):\n",
    "        gradient_vector[j] = net.der_cost_bias(layer_idx, j, activation_der_array[layer_idx - 1][j])\n",
    "\n",
    "    return gradient_vector\n",
    "\n",
    "def step(net: Net, weight_grad_matrices, biases_grad_matrices):\n",
    "    for i in range(net.layers_count - 1):\n",
    "        idx = i + 1\n",
    "        cur_layer = net.layers[idx]\n",
    "        cur_layer.weights += weight_grad_matrices[idx]\n",
    "        cur_layer.biases += biases_grad_matrices[idx]\n",
    "\n",
    "def training_iteration(training_data_item, target_vector, net: Net):\n",
    "    net.calc_output(training_data_item)\n",
    "    act_der_array = calc_activations_derivatives(net, target_vector)\n",
    "\n",
    "    weight_grad_matrices = []\n",
    "    biases_grad_matrices = []\n",
    "\n",
    "    for i in range(net.layers_count - 1):\n",
    "        idx = i + 1\n",
    "        weight_grad_matrices.append(get_weight_gradient_matrix(net, idx, act_der_array))\n",
    "        biases_grad_matrices.append(get_bias_gradient_matrix(net, idx, act_der_array))\n",
    "    # change net parameters\n",
    "    step(net, weight_grad_matrices, biases_grad_matrices)\n",
    "\n",
    "def calc_metric(net: Net, val_target_vectors):\n",
    "    predict_errors = []\n",
    "\n",
    "    for item in val_target_vectors:\n",
    "        last_layer = net.layers[net.layers_count - 1]\n",
    "        predict_errors = np.append(predict_errors, predict_error(last_layer.activations, item))\n",
    "\n",
    "    return np.mean(predict_errors)\n",
    "\n",
    "# net training on all training data items (returns metric on validation)\n",
    "def training(net: Net, training_data, target_vectors, val_target_vectors):\n",
    "    for training_item, target_vector in zip(training_data, target_vectors):\n",
    "        training_iteration(training_item, target_vector, net)\n",
    "    return calc_metric(net, val_target_vectors)\n",
    "\n",
    "# init weights and biases with start values\n",
    "def init_net_parameters(net: Net):\n",
    "    for i in range(net.layers_count - 1):\n",
    "        idx = i + 1\n",
    "        w_shape = net.layers[idx].weights.shape\n",
    "        b_shape = net.layers[idx].biases.shape\n",
    "\n",
    "        net.layers[idx].weights = rand.randn(w_shape[0], w_shape[1])\n",
    "        net.layers[idx].biases = rand.randn(b_shape[0], b_shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## generation of training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "periods_count = 100\n",
    "epsilon = 0.1\n",
    "st_points_count = 10\n",
    "\n",
    "dst_dir = \"../data_sets/\"\n",
    "training_data_file = open(dst_dir + \"cos_values_data\", \"w\")\n",
    "\n",
    "# 1 - write extremum points\n",
    "training_data_file.write(str(0) + \" \" + str(1) + \"\\n\")\n",
    "\n",
    "for i in range(periods_count - 1):\n",
    "    x = (np.pi / 2) * (i + 1)\n",
    "\n",
    "    val1 = np.cos(x)\n",
    "    val2 = np.cos(-x)\n",
    "    training_data_file.write(str(x) + \" \" + str(val1) + \"\\n\" + str(-x) + \" \" + str(val2) + \"\\n\")\n",
    "\n",
    "# write other points\n",
    "st_points = np.linspace(epsilon, np.pi / 2 - epsilon, st_points_count)\n",
    "\n",
    "for st_point in st_points:\n",
    "    for i in range(periods_count):\n",
    "        x = st_point + (np.pi / 2) * i\n",
    "        val1 = np.cos(x)\n",
    "        val2 = np.cos(-x)\n",
    "        training_data_file.write(str(x) + \" \" + str(val1) + \"\\n\" + str(-x) + \" \" + str(val2) + \"\\n\")\n",
    "\n",
    "training_data_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before shuffle: ['0 1\\n', '1.5707963267948966 6.123233995736766e-17\\n', '-1.5707963267948966 6.123233995736766e-17\\n', '3.141592653589793 -1.0\\n', '-3.141592653589793 -1.0\\n']\n",
      "after shuffle: ['78.53981633974483 -1.0\\n', '-55.83942495270743 0.7588552193149354\\n', '88.82614781540026 0.6512593616359621\\n', '136.40696972817878 -0.24964216559203725\\n', '154.95190424376312 -0.5285844158620803\\n']\n",
      "-------------------------\n",
      "first 5 training items: [[ 78.53981634]\n",
      " [-55.83942495]\n",
      " [ 88.82614782]\n",
      " [136.40696973]\n",
      " [154.95190424]]\n",
      "first 5 training target vectors: [[-1.        ]\n",
      " [ 0.75885522]\n",
      " [ 0.65125936]\n",
      " [-0.24964217]\n",
      " [-0.52858442]]\n"
     ]
    }
   ],
   "source": [
    "training_data_file = open(dst_dir + \"cos_values_data\", \"r\")\n",
    "training_data = np.array([])\n",
    "target_vectors = np.array([])\n",
    "lines = []\n",
    "items_count = 0\n",
    "\n",
    "# read lines and shuffle it\n",
    "for line in training_data_file:\n",
    "    lines.append(line)\n",
    "\n",
    "print(\"before shuffle: \" + str(lines[0:5]))\n",
    "rd.shuffle(lines)\n",
    "print(\"after shuffle: \" + str(lines[0:5]))\n",
    "print(\"-------------------------\")\n",
    "\n",
    "# get training data items and target vectors:\n",
    "for line in lines:\n",
    "    arg, value = line.split()\n",
    "    arg = float(arg)\n",
    "    value = float(value)\n",
    "\n",
    "    training_data = np.append(training_data, arg)\n",
    "    target_vectors = np.append(target_vectors, value)\n",
    "    items_count += 1\n",
    "\n",
    "# reshape data to array of 1-d vectors\n",
    "training_data = training_data.reshape((items_count, 1))\n",
    "target_vectors = target_vectors.reshape((items_count, 1))\n",
    "\n",
    "print(\"first 5 training items: \" + str(training_data[0:5]))\n",
    "print(\"first 5 training target vectors: \" + str(target_vectors[0:5]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split training data on batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches' count: 22\n",
      "---------\n",
      "training data batch 1:\n",
      "[[-151.04875808]\n",
      " [ 148.97334034]\n",
      " [-117.70972451]\n",
      " [ 109.24650006]\n",
      " [  47.0238898 ]\n",
      " [ 102.00176124]\n",
      " [ -34.80982989]\n",
      " [-102.00176124]\n",
      " [ -98.25092578]\n",
      " [ 132.19920215]\n",
      " [ -69.11503838]\n",
      " [ -84.26606954]\n",
      " [  11.40019569]\n",
      " [  86.49379797]\n",
      " [ 118.06203521]\n",
      " [-143.95632996]\n",
      " [   8.25860304]\n",
      " [ -17.8356917 ]\n",
      " [  27.86971248]\n",
      " [  23.6619449 ]\n",
      " [  60.09488182]\n",
      " [ -72.35663103]\n",
      " [ -10.99557429]\n",
      " [ 112.84502483]\n",
      " [-136.10234832]\n",
      " [ 142.53784433]\n",
      " [ 119.38052084]\n",
      " [  25.99429474]\n",
      " [  88.0645943 ]\n",
      " [  49.40392894]\n",
      " [ -25.84198404]\n",
      " [ -23.3096342 ]\n",
      " [  52.08858949]\n",
      " [ 100.63096491]\n",
      " [-154.03804003]\n",
      " [ -67.13962065]\n",
      " [   7.75398163]\n",
      " [ -49.70855035]\n",
      " [ 146.94561191]\n",
      " [ 155.76114706]\n",
      " [ -14.54178835]\n",
      " [  20.82497365]\n",
      " [  93.08160469]\n",
      " [ 134.37924129]\n",
      " [ -68.25348486]\n",
      " [  -3.85083547]\n",
      " [ 101.08789702]\n",
      " [-109.24650006]\n",
      " [ -55.99173566]\n",
      " [ -31.66823724]\n",
      " [  74.07973806]\n",
      " [   0.70924281]\n",
      " [ 120.39438505]\n",
      " [  18.84955592]\n",
      " [ -10.59095288]\n",
      " [-148.82102964]\n",
      " [  12.00943851]\n",
      " [ 103.77255757]\n",
      " [ 105.6479753 ]\n",
      " [   8.71553515]\n",
      " [  51.12703597]\n",
      " [ -88.97845852]\n",
      " [ 140.35780519]\n",
      " [ 107.06646093]\n",
      " [ -31.01130513]\n",
      " [-112.08347131]\n",
      " [  62.93185307]\n",
      " [ -39.67452958]\n",
      " [  23.5619449 ]\n",
      " [-151.50569018]\n",
      " [ -48.29006472]\n",
      " [ -36.98986903]\n",
      " [  -7.14473882]\n",
      " [  44.23460785]\n",
      " [ -76.56439861]\n",
      " [ -68.71041697]\n",
      " [  -4.15545687]\n",
      " [  76.71670931]\n",
      " [ -64.3026494 ]\n",
      " [  98.86016859]\n",
      " [  43.72998645]\n",
      " [ 113.50195694]\n",
      " [  12.56637061]\n",
      " [-155.10421495]\n",
      " [  77.98288423]\n",
      " [ 116.33892818]\n",
      " [  54.87787144]\n",
      " [ -78.13519493]\n",
      " [  26.14660545]\n",
      " [ -50.01317175]\n",
      " [-154.49497213]\n",
      " [-152.92417581]\n",
      " [   4.61238898]\n",
      " [-147.09792261]\n",
      " [-105.6479753 ]\n",
      " [  80.97216618]\n",
      " [ 138.33007676]\n",
      " [ 124.49753122]\n",
      " [-121.81287068]\n",
      " [ -58.98101761]]\n",
      "size=100\n",
      "---------\n",
      "target vectors batch 1:\n",
      "[[ 9.68338158e-01]\n",
      " [-2.49642166e-01]\n",
      " [-9.98334166e-02]\n",
      " [-7.58855219e-01]\n",
      " [-9.95004165e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-9.68338158e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-6.51259362e-01]\n",
      " [ 9.68338158e-01]\n",
      " [ 1.00000000e+00]\n",
      " [-8.48880743e-01]\n",
      " [ 3.93670765e-01]\n",
      " [ 9.98334166e-02]\n",
      " [ 2.49642166e-01]\n",
      " [ 8.48880743e-01]\n",
      " [-3.93670765e-01]\n",
      " [ 5.28584416e-01]\n",
      " [-9.19251504e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-9.19251504e-01]\n",
      " [-9.95004165e-01]\n",
      " [-4.28626380e-16]\n",
      " [ 9.68338158e-01]\n",
      " [-5.28584416e-01]\n",
      " [-3.93670765e-01]\n",
      " [ 1.00000000e+00]\n",
      " [ 6.51259362e-01]\n",
      " [ 9.95004165e-01]\n",
      " [ 6.51259362e-01]\n",
      " [ 7.58855219e-01]\n",
      " [-2.49642166e-01]\n",
      " [-2.49642166e-01]\n",
      " [ 9.95004165e-01]\n",
      " [-9.95004165e-01]\n",
      " [-3.93670765e-01]\n",
      " [ 9.98334166e-02]\n",
      " [ 8.48880743e-01]\n",
      " [-7.58855219e-01]\n",
      " [ 2.49642166e-01]\n",
      " [-3.93670765e-01]\n",
      " [-3.93670765e-01]\n",
      " [ 3.93670765e-01]\n",
      " [-7.58855219e-01]\n",
      " [ 6.51259362e-01]\n",
      " [-7.58855219e-01]\n",
      " [ 8.48880743e-01]\n",
      " [-7.58855219e-01]\n",
      " [ 8.48880743e-01]\n",
      " [ 9.68338158e-01]\n",
      " [ 2.49642166e-01]\n",
      " [ 7.58855219e-01]\n",
      " [ 5.28584416e-01]\n",
      " [ 1.00000000e+00]\n",
      " [-3.93670765e-01]\n",
      " [-3.93670765e-01]\n",
      " [ 8.48880743e-01]\n",
      " [-9.95004165e-01]\n",
      " [ 3.93670765e-01]\n",
      " [-7.58855219e-01]\n",
      " [ 6.51259362e-01]\n",
      " [ 5.28584416e-01]\n",
      " [-5.28584416e-01]\n",
      " [ 9.68338158e-01]\n",
      " [ 9.19251504e-01]\n",
      " [ 5.28584416e-01]\n",
      " [ 9.95004165e-01]\n",
      " [-3.93670765e-01]\n",
      " [-2.69484194e-15]\n",
      " [ 7.58855219e-01]\n",
      " [-3.93670765e-01]\n",
      " [ 7.58855219e-01]\n",
      " [ 6.51259362e-01]\n",
      " [ 9.68338158e-01]\n",
      " [ 3.93670765e-01]\n",
      " [ 9.19251504e-01]\n",
      " [-5.28584416e-01]\n",
      " [ 2.49642166e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-9.98334166e-02]\n",
      " [ 9.68338158e-01]\n",
      " [ 9.19251504e-01]\n",
      " [ 1.00000000e+00]\n",
      " [-3.93670765e-01]\n",
      " [-8.48880743e-01]\n",
      " [-9.95004165e-01]\n",
      " [-9.98334166e-02]\n",
      " [-9.19251504e-01]\n",
      " [ 5.28584416e-01]\n",
      " [ 9.68338158e-01]\n",
      " [-8.48880743e-01]\n",
      " [-5.28584416e-01]\n",
      " [-9.98334166e-02]\n",
      " [-8.48880743e-01]\n",
      " [ 3.93670765e-01]\n",
      " [ 7.58855219e-01]\n",
      " [ 9.95004165e-01]\n",
      " [ 3.93670765e-01]\n",
      " [-7.58855219e-01]\n",
      " [-7.58855219e-01]]\n",
      "size=100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "data_size = len(training_data)\n",
    "batch_count = data_size // batch_size\n",
    "rem = data_size % batch_size\n",
    "training_data_batches = []\n",
    "target_vectors_batches = []\n",
    "\n",
    "if data_size % batch_size != 0:\n",
    "    batch_count += 1\n",
    "\n",
    "for i in range(batch_count):\n",
    "    pos = i * batch_size\n",
    "    tr_data_batch = []\n",
    "    t_vectors_batch = []\n",
    "\n",
    "    if i == batch_count - 1:\n",
    "        tr_data_batch = training_data[pos:]\n",
    "        t_vectors_batch = target_vectors[pos:]\n",
    "    else:\n",
    "        tr_data_batch = training_data[pos:pos + batch_size]\n",
    "        t_vectors_batch = target_vectors[pos:pos + batch_size]\n",
    "    training_data_batches.append(tr_data_batch)\n",
    "    target_vectors_batches.append(t_vectors_batch)\n",
    "\n",
    "print(\"batches' count: \" + str(batch_count))\n",
    "print(\"---------\")\n",
    "idx = 1\n",
    "print(\"training data batch \" + str(idx) + \":\\n\" + str(training_data_batches[idx]))\n",
    "print(\"size=\" + str(len(training_data_batches[idx])))\n",
    "\n",
    "print(\"---------\")\n",
    "print(\"target vectors batch \" + str(idx) + \":\\n\" + str(target_vectors_batches[idx]))\n",
    "print(\"size=\" + str(len(target_vectors_batches[idx])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}