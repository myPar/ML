{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from TPNN.tools.perceptron import*\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import numpy.random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "layers=3\n",
      "[0]\n",
      " size=2\n",
      " act_function=<function ident at 0x062924A8>\n",
      " activations=[[0. 0.]]\n",
      " biases=[[0. 0.]]\n",
      " weights:\n",
      "     empty\n",
      "--------------------------\n",
      "[1]\n",
      " size=5\n",
      " act_function=<function sigmoid at 0x0A641730>\n",
      " activations=[[0. 0. 0. 0. 0.]]\n",
      " biases=[[1 1 1 1 1]]\n",
      " weights:\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "\n",
      "--------------------------\n",
      "[2]\n",
      " size=1\n",
      " act_function=<function ident at 0x062924A8>\n",
      " activations=[[0.]]\n",
      " biases=[[0]]\n",
      " weights:\n",
      "     |1 |\n",
      "     |1 |\n",
      "     |1 |\n",
      "     |1 |\n",
      "     |1 |\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.insert_layer(0, 2, ident)\n",
    "net.insert_layer(1, 5, sigmoid)\n",
    "net.insert_layer(2, 1, ident)\n",
    "print(net.layers_count)\n",
    "net.init_weights(1, np.array([[1,1,1,1,1], [1,1,1,1,1]]))\n",
    "net.init_weights(2, np.array([[1,1,1,1,1]]).transpose())\n",
    "net.init_biases(2, np.array([[0]]))\n",
    "net.init_biases(1, np.array([[1,1,1,1,1]]))\n",
    "\n",
    "net.print_net_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.76287063]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calc_output(np.array([1, 1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers=4\n",
      "[0]\n",
      " size=5\n",
      " act_function=<function ident at 0x062924A8>\n",
      " activations=[[0. 0. 0. 0. 0.]]\n",
      " biases=[[0. 0. 0. 0. 0.]]\n",
      " weights:\n",
      "     empty\n",
      "--------------------------\n",
      "[1]\n",
      " size=7\n",
      " act_function=<function sigmoid at 0x0A641730>\n",
      " activations=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " biases=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " weights:\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "\n",
      "--------------------------\n",
      "[2]\n",
      " size=7\n",
      " act_function=<function th at 0x0A641778>\n",
      " activations=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " biases=[[0. 0. 0. 0. 0. 0. 0.]]\n",
      " weights:\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 -4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "     |1 2 3 4 5 6 7 |\n",
      "\n",
      "--------------------------\n",
      "[3]\n",
      " size=5\n",
      " act_function=<function ident at 0x062924A8>\n",
      " activations=[[0. 0. 0. 0. 0.]]\n",
      " biases=[[1 1 1 1 1]]\n",
      " weights:\n",
      "     |1 1 0 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 0 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "     |1 1 1 1 1 |\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.insert_layer(0, 5, ident)\n",
    "net.insert_layer(1, 7, sigmoid)\n",
    "net.insert_layer(2, 7, th)\n",
    "net.insert_layer(3, 5, ident)\n",
    "\n",
    "net.init_weights(1, np.array([[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7]]))\n",
    "net.init_weights(2, np.array([[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,-4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7]]))\n",
    "net.init_weights(3, np.array([[1,1,0,1,1],[1,1,1,1,1],[1,1,1,0,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]]))\n",
    "net.init_biases(3, np.array([[1,1,1,1,1]]))\n",
    "\n",
    "net.print_net_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[7.99999833, 7.99999833, 7.        , 6.99999833, 7.99999833]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calc_output(np.array([1,2,0,2,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fill activation derivatives array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def calc_activations_derivatives(net: Net, target_vector):\n",
    "    last_layer = net.layers[net.layers_count - 1]\n",
    "    activation_der_array = []\n",
    "    last_layer_derivatives_array = []\n",
    "\n",
    "    for i in range(last_layer.neuron_count):\n",
    "        der = predict_error_der(last_layer.activations[0], target_vector, i)\n",
    "        last_layer_derivatives_array.append(der)\n",
    "\n",
    "    activation_der_array.insert(0, last_layer_derivatives_array)\n",
    "\n",
    "    # cal derivatives on each layer, except last and first layers\n",
    "    cur_iteration = 0\n",
    "    for i in range(net.layers_count - 2, 0, -1):\n",
    "        cur_layer = net.layers[i]\n",
    "        layer_derivatives_array = []\n",
    "\n",
    "        for j in range(cur_layer.neuron_count):\n",
    "            next_layer_der_array = activation_der_array[0]\n",
    "            layer_derivatives_array.append(net.der_cost_act(i, j, next_layer_der_array))\n",
    "\n",
    "        # add derivatives array of the current layer\n",
    "        activation_der_array.insert(0, layer_derivatives_array)\n",
    "        cur_iteration += 1\n",
    "\n",
    "    return activation_der_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Net training functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_weight_gradient_matrix(net: Net, layer_idx, activation_der_array):\n",
    "    assert 0 < layer_idx < net.layers_count\n",
    "    prev_layer_neuron_count = net.layers[layer_idx - 1].neuron_count\n",
    "    cur_layer_neuron_count = net.layers[layer_idx].neuron_count\n",
    "\n",
    "    gradient_matrix = np.zeros((prev_layer_neuron_count, cur_layer_neuron_count))\n",
    "\n",
    "    for i in range(prev_layer_neuron_count):\n",
    "        for j in range(cur_layer_neuron_count):\n",
    "            gradient_matrix[i][j] = net.der_cost_weigh(layer_idx, i, j, activation_der_array[layer_idx - 1][j])\n",
    "    return gradient_matrix\n",
    "\n",
    "def get_bias_gradient_matrix(net: Net, layer_idx, activation_der_array):\n",
    "    assert 0 < layer_idx < net.layers_count\n",
    "    cur_layer_neuron_count = net.layers[layer_idx].neuron_count\n",
    "    gradient_vector = np.zeros(cur_layer_neuron_count)\n",
    "\n",
    "    for j in range(cur_layer_neuron_count):\n",
    "        gradient_vector[j] = net.der_cost_bias(layer_idx, j, activation_der_array[layer_idx - 1][j])\n",
    "\n",
    "    return gradient_vector\n",
    "\n",
    "def step(net: Net, weight_grad_matrices, biases_grad_matrices):\n",
    "    for i in range(net.layers_count - 1):\n",
    "        idx = i + 1\n",
    "        cur_layer = net.layers[idx]\n",
    "        cur_layer.weights += weight_grad_matrices[idx - 1]\n",
    "        cur_layer.biases += biases_grad_matrices[idx - 1]\n",
    "\n",
    "def training_iteration(training_data_item, target_vector, net: Net):\n",
    "    net.calc_output(training_data_item)\n",
    "    act_der_array = calc_activations_derivatives(net, target_vector)\n",
    "\n",
    "    weight_grad_matrices = []\n",
    "    biases_grad_matrices = []\n",
    "\n",
    "    for i in range(net.layers_count - 1):\n",
    "        idx = i + 1\n",
    "        weight_grad_matrices.append(get_weight_gradient_matrix(net, idx, act_der_array))\n",
    "        biases_grad_matrices.append(get_bias_gradient_matrix(net, idx, act_der_array))\n",
    "    # change net parameters\n",
    "    step(net, weight_grad_matrices, biases_grad_matrices)\n",
    "\n",
    "def calc_metric(net: Net, val_target_vectors):\n",
    "    predict_errors = []\n",
    "\n",
    "    for item in val_target_vectors:\n",
    "        last_layer = net.layers[net.layers_count - 1]\n",
    "        predict_errors = np.append(predict_errors, predict_error(last_layer.activations, item))\n",
    "\n",
    "    return np.mean(predict_errors)\n",
    "\n",
    "# net training on all training data items (returns metric on validation)\n",
    "def training(net: Net, training_data, target_vectors, val_target_vectors):\n",
    "    for training_item, target_vector in zip(training_data, target_vectors):\n",
    "        training_iteration(training_item, target_vector, net)\n",
    "    return calc_metric(net, val_target_vectors)\n",
    "\n",
    "# init weights and biases with start values\n",
    "def init_net_parameters(net: Net):\n",
    "    for i in range(net.layers_count - 1):\n",
    "        idx = i + 1\n",
    "        w_shape = net.layers[idx].weights.shape\n",
    "        b_shape = net.layers[idx].biases.shape\n",
    "\n",
    "        net.layers[idx].weights = rand.randn(w_shape[0], w_shape[1])\n",
    "        net.layers[idx].biases = rand.randn(b_shape[0], b_shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## generation of training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "periods_count = 100\n",
    "epsilon = 0.1\n",
    "st_points_count = 10\n",
    "\n",
    "dst_dir = \"../data_sets/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "training_data_file = open(dst_dir + \"cos_values_data\", \"w\")\n",
    "\n",
    "# 1 - write extremum points\n",
    "training_data_file.write(str(0) + \" \" + str(1) + \"\\n\")\n",
    "\n",
    "for i in range(periods_count - 1):\n",
    "    x = (np.pi / 2) * (i + 1)\n",
    "\n",
    "    val1 = np.cos(x)\n",
    "    val2 = np.cos(-x)\n",
    "    training_data_file.write(str(x) + \" \" + str(val1) + \"\\n\" + str(-x) + \" \" + str(val2) + \"\\n\")\n",
    "\n",
    "# write other points\n",
    "st_points = np.linspace(epsilon, np.pi / 2 - epsilon, st_points_count)\n",
    "\n",
    "for st_point in st_points:\n",
    "    for i in range(periods_count):\n",
    "        x = st_point + (np.pi / 2) * i\n",
    "        val1 = np.cos(x)\n",
    "        val2 = np.cos(-x)\n",
    "        training_data_file.write(str(x) + \" \" + str(val1) + \"\\n\" + str(-x) + \" \" + str(val2) + \"\\n\")\n",
    "\n",
    "training_data_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before shuffle: ['0 1\\n', '1.5707963267948966 6.123233995736766e-17\\n', '-1.5707963267948966 6.123233995736766e-17\\n', '3.141592653589793 -1.0\\n', '-3.141592653589793 -1.0\\n']\n",
      "after shuffle: ['-115.6819960738907 -0.8488807426887105\\n', '-74.99360228020062 0.9192515044496764\\n', '132.65613426268015 0.7588552193149402\\n', '18.84955592153876 1.0\\n', '66.53037783431729 -0.848880742688718\\n']\n",
      "-------------------------\n",
      "first 5 training items: [[-115.68199607]\n",
      " [ -74.99360228]\n",
      " [ 132.65613426]\n",
      " [  18.84955592]\n",
      " [  66.53037783]]\n",
      "first 5 training target vectors: [[-0.84888074]\n",
      " [ 0.9192515 ]\n",
      " [ 0.75885522]\n",
      " [ 1.        ]\n",
      " [-0.84888074]]\n"
     ]
    }
   ],
   "source": [
    "training_data_file = open(dst_dir + \"cos_values_data\", \"r\")\n",
    "training_data = np.array([])\n",
    "target_vectors = np.array([])\n",
    "lines = []\n",
    "items_count = 0\n",
    "\n",
    "# read lines and shuffle it\n",
    "for line in training_data_file:\n",
    "    lines.append(line)\n",
    "\n",
    "print(\"before shuffle: \" + str(lines[0:5]))\n",
    "rd.shuffle(lines)\n",
    "print(\"after shuffle: \" + str(lines[0:5]))\n",
    "print(\"-------------------------\")\n",
    "\n",
    "# get training data items and target vectors:\n",
    "for line in lines:\n",
    "    arg, value = line.split()\n",
    "    arg = float(arg)\n",
    "    value = float(value)\n",
    "\n",
    "    training_data = np.append(training_data, arg)\n",
    "    target_vectors = np.append(target_vectors, value)\n",
    "    items_count += 1\n",
    "\n",
    "# reshape data to array of 1-d vectors\n",
    "training_data = training_data.reshape((items_count, 1))\n",
    "target_vectors = target_vectors.reshape((items_count, 1))\n",
    "\n",
    "print(\"first 5 training items: \" + str(training_data[0:5]))\n",
    "print(\"first 5 training target vectors: \" + str(target_vectors[0:5]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split training data on batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches' count: 22\n",
      "---------\n",
      "training data batch 1:\n",
      "[[  70.78583471]\n",
      " [ 148.51640823]\n",
      " [ -78.13519493]\n",
      " [ 152.114933  ]\n",
      " [  -5.11701039]\n",
      " [-107.67570374]\n",
      " [  88.52152641]\n",
      " [  58.11946409]\n",
      " [  34.00058708]\n",
      " [ -28.67895529]\n",
      " [ -98.86016859]\n",
      " [  47.37620051]\n",
      " [ 127.48681317]\n",
      " [ -25.53736263]\n",
      " [ -83.50451602]\n",
      " [-117.90972451]\n",
      " [ -77.83057353]\n",
      " [  64.95958151]\n",
      " [ 148.97334034]\n",
      " [ -86.49379797]\n",
      " [  92.27236187]\n",
      " [   4.00314617]\n",
      " [ 105.2433539 ]\n",
      " [  81.27678759]\n",
      " [  61.66567815]\n",
      " [  48.69468613]\n",
      " [-153.93804003]\n",
      " [   0.55693211]\n",
      " [ -63.54109588]\n",
      " [  72.66125244]\n",
      " [  77.98288423]\n",
      " [ -62.57954237]\n",
      " [  20.32035225]\n",
      " [  96.83244015]\n",
      " [  51.12703597]\n",
      " [-130.47609512]\n",
      " [ -96.83244015]\n",
      " [ 115.98661748]\n",
      " [ 131.54227004]\n",
      " [  86.49379797]\n",
      " [ -70.2812133 ]\n",
      " [  83.96144813]\n",
      " [ 109.70343217]\n",
      " [ 149.47796175]\n",
      " [  30.70668372]\n",
      " [ -36.83755833]\n",
      " [-130.37609512]\n",
      " [-143.19477644]\n",
      " [  16.11258467]\n",
      " [   2.73697125]\n",
      " [-133.76999848]\n",
      " [ -65.56882432]\n",
      " [ -33.23903357]\n",
      " [ -92.12005117]\n",
      " [-132.35151286]\n",
      " [  34.65751919]\n",
      " [  97.79399367]\n",
      " [  34.30520849]\n",
      " [  48.44237543]\n",
      " [ -89.43539063]\n",
      " [ 114.11119975]\n",
      " [ 102.65869335]\n",
      " [  58.8287069 ]\n",
      " [  39.36990817]\n",
      " [ -79.55368056]\n",
      " [-142.53784433]\n",
      " [-117.70972451]\n",
      " [  78.53981634]\n",
      " [ -33.69596567]\n",
      " [  31.66823724]\n",
      " [ 137.36852324]\n",
      " [ -84.11375884]\n",
      " [ -59.79026042]\n",
      " [-155.60883635]\n",
      " [ -38.10373325]\n",
      " [  45.14847207]\n",
      " [ 111.6265392 ]\n",
      " [ 115.68199607]\n",
      " [  33.69596567]\n",
      " [ -52.5455216 ]\n",
      " [  19.40648803]\n",
      " [ 133.61768778]\n",
      " [ -72.50894174]\n",
      " [  17.17875959]\n",
      " [ -24.72811982]\n",
      " [  75.80284509]\n",
      " [ -29.1358874 ]\n",
      " [ -35.1144513 ]\n",
      " [  77.22133072]\n",
      " [   0.        ]\n",
      " [  43.88229715]\n",
      " [ -80.51523407]\n",
      " [-154.49497213]\n",
      " [ 144.91788347]\n",
      " [ -89.78770133]\n",
      " [ 145.52712628]\n",
      " [ -14.54178835]\n",
      " [ -90.70156555]\n",
      " [  29.4405088 ]\n",
      " [ 139.39625168]]\n",
      "size=100\n",
      "---------\n",
      "target vectors batch 1:\n",
      "[[-9.98334166e-02]\n",
      " [-6.51259362e-01]\n",
      " [-9.19251504e-01]\n",
      " [ 2.49642166e-01]\n",
      " [ 3.93670765e-01]\n",
      " [ 6.51259362e-01]\n",
      " [ 8.48880743e-01]\n",
      " [ 4.89239739e-16]\n",
      " [-8.48880743e-01]\n",
      " [-9.19251504e-01]\n",
      " [-9.98334166e-02]\n",
      " [-9.68338158e-01]\n",
      " [-2.49642166e-01]\n",
      " [ 9.19251504e-01]\n",
      " [-2.49642166e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-7.58855219e-01]\n",
      " [-5.28584416e-01]\n",
      " [-2.49642166e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-3.93670765e-01]\n",
      " [-6.51259362e-01]\n",
      " [-5.87892362e-15]\n",
      " [ 9.19251504e-01]\n",
      " [ 3.93670765e-01]\n",
      " [-3.67455938e-15]\n",
      " [-1.00000000e+00]\n",
      " [ 8.48880743e-01]\n",
      " [ 7.58855219e-01]\n",
      " [-9.19251504e-01]\n",
      " [-8.48880743e-01]\n",
      " [ 9.68338158e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-8.48880743e-01]\n",
      " [ 6.51259362e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-8.48880743e-01]\n",
      " [-9.68338158e-01]\n",
      " [ 9.19251504e-01]\n",
      " [ 9.98334166e-02]\n",
      " [ 3.93670765e-01]\n",
      " [-6.51259362e-01]\n",
      " [-9.68338158e-01]\n",
      " [ 2.49642166e-01]\n",
      " [ 7.58855219e-01]\n",
      " [ 6.51259362e-01]\n",
      " [ 7.35221366e-15]\n",
      " [ 2.49642166e-01]\n",
      " [-9.19251504e-01]\n",
      " [-9.19251504e-01]\n",
      " [-2.49642166e-01]\n",
      " [-9.19251504e-01]\n",
      " [-2.49642166e-01]\n",
      " [-5.28584416e-01]\n",
      " [ 9.19251504e-01]\n",
      " [-9.95004165e-01]\n",
      " [-9.19251504e-01]\n",
      " [-9.68338158e-01]\n",
      " [-2.49642166e-01]\n",
      " [ 9.98334166e-02]\n",
      " [ 5.28584416e-01]\n",
      " [-5.28584416e-01]\n",
      " [-6.51259362e-01]\n",
      " [-9.98334166e-02]\n",
      " [-5.28584416e-01]\n",
      " [-3.93670765e-01]\n",
      " [-9.98334166e-02]\n",
      " [-1.00000000e+00]\n",
      " [-6.51259362e-01]\n",
      " [ 9.68338158e-01]\n",
      " [ 6.51259362e-01]\n",
      " [-7.58855219e-01]\n",
      " [-9.95004165e-01]\n",
      " [ 9.98334166e-02]\n",
      " [ 9.19251504e-01]\n",
      " [ 3.93670765e-01]\n",
      " [ 9.98334166e-02]\n",
      " [-8.48880743e-01]\n",
      " [-6.51259362e-01]\n",
      " [-6.51259362e-01]\n",
      " [ 8.48880743e-01]\n",
      " [-9.98334166e-02]\n",
      " [-9.68338158e-01]\n",
      " [-9.98334166e-02]\n",
      " [ 9.19251504e-01]\n",
      " [ 9.19251504e-01]\n",
      " [-6.51259362e-01]\n",
      " [-8.48880743e-01]\n",
      " [-2.49642166e-01]\n",
      " [ 1.00000000e+00]\n",
      " [ 9.95004165e-01]\n",
      " [ 3.93670765e-01]\n",
      " [-8.48880743e-01]\n",
      " [ 9.19251504e-01]\n",
      " [-2.49642166e-01]\n",
      " [ 5.28584416e-01]\n",
      " [-3.93670765e-01]\n",
      " [-9.19251504e-01]\n",
      " [-3.93670765e-01]\n",
      " [ 3.93670765e-01]]\n",
      "size=100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "data_size = len(training_data)\n",
    "batch_count = data_size // batch_size\n",
    "rem = data_size % batch_size\n",
    "training_data_batches = []\n",
    "target_vectors_batches = []\n",
    "\n",
    "if data_size % batch_size != 0:\n",
    "    batch_count += 1\n",
    "\n",
    "for i in range(batch_count):\n",
    "    pos = i * batch_size\n",
    "    tr_data_batch = []\n",
    "    t_vectors_batch = []\n",
    "\n",
    "    if i == batch_count - 1:\n",
    "        tr_data_batch = training_data[pos:]\n",
    "        t_vectors_batch = target_vectors[pos:]\n",
    "    else:\n",
    "        tr_data_batch = training_data[pos:pos + batch_size]\n",
    "        t_vectors_batch = target_vectors[pos:pos + batch_size]\n",
    "    training_data_batches.append(tr_data_batch)\n",
    "    target_vectors_batches.append(t_vectors_batch)\n",
    "\n",
    "print(\"batches' count: \" + str(batch_count))\n",
    "print(\"---------\")\n",
    "idx = 1\n",
    "print(\"training data batch \" + str(idx) + \":\\n\" + str(training_data_batches[idx]))\n",
    "print(\"size=\" + str(len(training_data_batches[idx])))\n",
    "\n",
    "print(\"---------\")\n",
    "print(\"target vectors batch \" + str(idx) + \":\\n\" + str(target_vectors_batches[idx]))\n",
    "print(\"size=\" + str(len(target_vectors_batches[idx])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create net and train it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "layers=3\n",
      "[0]\n",
      " size=1\n",
      " act_function=<function ident at 0x062924A8>\n",
      " activations=[[0.]]\n",
      " biases=[[0.]]\n",
      " weights:\n",
      "     empty\n",
      "--------------------------\n",
      "[1]\n",
      " size=10\n",
      " act_function=<function th at 0x0A641778>\n",
      " activations=[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      " biases=[[-1.32911375 -1.45747774  0.10639789 -0.60684581  0.6162194  -0.20473125\n",
      "   0.08784803  1.19751599  0.3093872  -0.949713  ]]\n",
      " weights:\n",
      "     |0.9230829723572704 -1.1286882003775778 0.7155939435449482 0.6646651990550531 -0.17644824313457577 -0.7544506331551675 -0.2751670278127521 -0.670684504071213 -1.2944525895817443 -1.0552538550215833 |\n",
      "\n",
      "--------------------------\n",
      "[2]\n",
      " size=1\n",
      " act_function=<function th at 0x0A641778>\n",
      " activations=[[0.]]\n",
      " biases=[[-1.29238629]]\n",
      " weights:\n",
      "     |-1.7023570876667418 |\n",
      "     |1.4838065217835346 |\n",
      "     |-0.7430153538942152 |\n",
      "     |-0.606831835002515 |\n",
      "     |-1.412482318869308 |\n",
      "     |1.2908637090724704 |\n",
      "     |1.15545006276706 |\n",
      "     |0.25302548024565574 |\n",
      "     |0.07479927188256112 |\n",
      "     |-1.561379273135107 |\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# net parameters\n",
    "net = Net()\n",
    "hidden_layers_size = 10\n",
    "hidden_layers_count = 1\n",
    "activation = th\n",
    "\n",
    "net.insert_layer(0, 1, ident)\n",
    "\n",
    "for i in range(hidden_layers_count):\n",
    "    net.insert_layer(1, hidden_layers_size, activation)\n",
    "net.insert_layer(hidden_layers_count + 1, 1, activation)\n",
    "print(net.layers_count)\n",
    "\n",
    "for i in range(hidden_layers_count):\n",
    "    idx = i + 1\n",
    "    cur_layer = net.layers[idx]\n",
    "\n",
    "    if i == 0:\n",
    "        cur_layer.weights = np.zeros((1, hidden_layers_size))\n",
    "    else:\n",
    "        cur_layer.weights = np.zeros((hidden_layers_size, hidden_layers_size))\n",
    "    cur_layer.biases = np.zeros((1, hidden_layers_size))\n",
    "\n",
    "net.init_weights(net.layers_count - 1, np.zeros((hidden_layers_size, 1)))\n",
    "net.init_biases(net.layers_count - 1, np.zeros((1, 1)))\n",
    "\n",
    "# init all net parameters with values from standart normal destribution\n",
    "init_net_parameters(net)\n",
    "\n",
    "net.print_net_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 1.0001639728161256\n",
      "epoch 1: 0.999545245733181\n",
      "epoch 2: 0.9995452456950548\n",
      "epoch 3: 0.999545246213225\n",
      "epoch 4: 0.999545246425895\n",
      "epoch 5: 1.0004546812258035\n",
      "epoch 6: 1.000454681511304\n",
      "epoch 7: 0.9995452476879604\n",
      "epoch 8: 0.9995452478382576\n",
      "epoch 9: 0.9995448699321536\n",
      "epoch 10: 1.0004547518984996\n",
      "epoch 11: 0.9995452478398313\n",
      "epoch 12: 1.0004547518967524\n",
      "epoch 13: 1.000454751898518\n",
      "epoch 14: 1.0004547518985183\n",
      "epoch 15: 0.9995452478393196\n",
      "epoch 16: 1.0004547518985316\n",
      "epoch 17: 0.9995452478393196\n",
      "epoch 18: 0.9995452478393196\n",
      "epoch 19: 1.000454751898519\n",
      "epoch 20: 1.000454751898523\n",
      "epoch 21: 0.9995452478393196\n"
     ]
    }
   ],
   "source": [
    "min_cost = 0.05\n",
    "\n",
    "for i in range(batch_count):\n",
    "    training_batch = training_data_batches[i]\n",
    "    target_vectors_batch = target_vectors_batches[i]\n",
    "\n",
    "    cost = training(net, training_batch, target_vectors_batch, target_vectors)\n",
    "    print(\"epoch \" + str(i) + \": \" + str(cost))\n",
    "\n",
    "    if cost <= min_cost:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}