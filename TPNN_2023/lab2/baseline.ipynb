{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from TPNN_2023.lab2.Perceptron import *\n",
    "from TPNN_2023.lab2.activation_functions import *\n",
    "from TPNN_2023.lab2.tools import default_init, test_init, Adam\n",
    "from TPNN_2023.lab2.metrics import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test output calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers count=3\n",
      "layers:\n",
      "[0]\n",
      "  Dense layer:\n",
      "    neuron count=12\n",
      "  weight matrix:\n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 \n",
      "  biases:\n",
      "    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0\n",
      "  weigh's gradient:\n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "  biases gradient:\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "[1]\n",
      "  Dense layer:\n",
      "    neuron count=10\n",
      "  weight matrix:\n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "    1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 \n",
      "  biases:\n",
      "    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0\n",
      "  weigh's gradient:\n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "  biases gradient:\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "[2]\n",
      "  Softmax layer:\n",
      "  dimension: 10\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.add_layer(Dense(neuron_count=12, act_function=sigmoid))\n",
    "net.add_layer(Dense(neuron_count=10, act_function=th))\n",
    "net.add_layer(Softmax(10))\n",
    "net.init_net(init_strategy=test_init, input_shape=(5, ))\n",
    "net.print_net_config(ConfigLevel.HIGH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.calc_output(np.array([1,1,1,1,1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test backpropagation step"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers count=3\n",
      "layers:\n",
      "[0]\n",
      "  Dense layer:\n",
      "    neuron count=12\n",
      "  weight matrix:\n",
      "    0.21779689437030791 0.09014772855395836 0.05739673671212597 -0.3758892710925107 -0.3796220494771274 \n",
      "    -0.4205799673274656 0.18670647755400338 -0.1968059672512713 -0.37433318135243043 -0.173565298991897 \n",
      "    0.38979443047632223 -0.266751428760753 0.48216799870597715 0.17772657264517144 0.02718401366279355 \n",
      "    0.4603364080275426 0.17881733295488356 0.4696194572191509 0.3680492328107571 0.08214729929070819 \n",
      "    0.32877321943248283 -0.41686954325581016 0.21031067145303206 -0.16652415290846512 0.4854218914335173 \n",
      "    -0.07415453186902132 0.36037948327421365 0.0013618263784431761 0.11754547278430183 -0.05736664590188967 \n",
      "    0.2523278465144738 0.0748253739574346 0.3678051392110766 0.05275093746281889 -0.4552517315373067 \n",
      "    -0.015744657195695733 0.08642124033125487 0.35847658062033627 -0.27738593475825346 0.17923103767462967 \n",
      "    -0.08982012122079219 0.13925449426661785 0.10571164668725852 0.17233740327194114 0.22593618697703233 \n",
      "    0.4271469582051298 0.04379209133547435 0.41131264524026934 0.17683390605563987 -0.09504163843635782 \n",
      "    -0.3425627492977703 0.31647080158863694 0.06725964031633247 0.45601112421384915 0.4180969561954817 \n",
      "    0.47303132608963216 0.29607098882263194 -0.32419023817971293 -0.43838945337996627 -0.34984197342648005 \n",
      "  biases:\n",
      "    -0.14111734438035262    -0.15290756614877865    0.024543557429862473    0.1322230073807451    0.009169761478590943    0.11271416982504323    0.48252679349372185    0.4860503861836869    -0.12553192626946696    0.32886338782645874    -0.008049408219471865    -0.24143117764273214\n",
      "  weigh's gradient:\n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 \n",
      "  biases gradient:\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "[1]\n",
      "  Dense layer:\n",
      "    neuron count=10\n",
      "  weight matrix:\n",
      "    0.4363302853819845 0.2784697831711057 0.41191644348177636 0.24278845947213712 0.23597335088006421 -0.18191024496828645 -0.33814682445242605 0.08207270925446586 0.0800764406478518 0.492646563731474 0.37465795829378545 0.027069768575826436 \n",
      "    0.17736910142411288 0.08164101059855966 0.41556286240115514 0.2984167974472306 0.198132084916119 0.49989531405470555 -0.07082386321936829 0.3427750507298485 -0.14568102250067194 0.30705844986707787 0.04986084640167965 -0.4187035058690194 \n",
      "    -0.1713446083529624 -0.18365678191985602 0.2420593500843753 0.2493534046708522 0.20416563204323712 -0.0622322605809188 -0.12099007453710497 0.3837270892984114 -0.17593950803430802 -0.17064664421233067 0.12831843883011462 -0.28949799031773327 \n",
      "    0.44829961427072385 -0.19942906325798881 -0.13240774303117264 -0.03796111130530422 -0.4043753781093864 0.4466760078333504 0.1193190171011973 0.2813024504022805 0.17819231162254634 -0.4967774005158577 0.018272372799435388 0.3787268033167731 \n",
      "    0.44687215543978664 -0.07881253907816965 0.17331469331576232 -0.30429354615113025 -0.42424154974389083 0.2240989473021553 0.31982798455395534 -0.44148635098973965 -0.38687507973017454 -0.2119766335334322 0.04833341885508058 -0.3257235227643235 \n",
      "    0.007689148041420291 -0.3181867386039462 -0.4221702379093496 -0.23699253440643764 0.20155354958694205 -0.22577533931428817 0.012744117649783115 0.44494445708255015 -0.30639917151653984 -0.08371919435059438 -0.15615371876529016 -0.3920360568888247 \n",
      "    -0.3737171569216716 -0.17912966437970124 0.3061891646731817 -0.016696046918072138 0.2809845373968308 -0.32666146956324016 0.38110818201343655 -0.40258014010440224 -0.025564323700018265 -0.3276421319403985 0.17620228611975308 -0.42005911332826384 \n",
      "    0.1702602611970231 0.0068578933445749835 -0.3643083416462102 -0.10752293763071408 -0.2365463189661171 0.3106006342253421 -0.10071565022868068 -0.07372075148209323 -0.3198041656816759 -0.03757826872311232 -0.48987790806432885 -0.2676542134884935 \n",
      "    0.3830076799826774 -0.13200834607834 0.14812622054336533 -0.38583317335113965 0.3531898506801754 -0.41897213480192774 0.2993308411575698 -0.06572247306154688 0.019833727175351812 -0.3975874916208123 0.2055348014386008 0.20566972906236514 \n",
      "    -0.2898737840743987 0.14131500854078394 -0.26798001965731755 -0.04948058716178705 -0.3152676401516751 -0.36149942133247537 -0.36484282121923584 -0.2815267737831161 -0.18922223197910504 0.060134586626186204 -0.26113076622406173 0.32321165999002055 \n",
      "  biases:\n",
      "    -0.40757244960742756    0.4173609704575125    0.4077683813731965    0.3644454416644727    0.019630499637688703    -0.37082862508996517    0.37392657027781384    -0.08361503581655916    0.26033262477530905    -0.3420957588011456\n",
      "  weigh's gradient:\n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "  biases gradient:\n",
      "    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "[2]\n",
      "  Softmax layer:\n",
      "  dimension: 10\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.add_layer(Dense(neuron_count=12, act_function=sigmoid))\n",
    "net.add_layer(Dense(neuron_count=10, act_function=th))\n",
    "net.add_layer(Softmax(10))\n",
    "net.init_net(init_strategy=default_init, input_shape=(5, ))\n",
    "net.print_net_config(ConfigLevel.HIGH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers count=3\n",
      "layers:\n",
      "[0]\n",
      "  Dense layer:\n",
      "    neuron count=12\n",
      "  weight matrix:\n",
      "    0.21793896380047104 0.0902897979841215 0.05753880614228911 -0.37574720166234754 -0.37947998004696426 \n",
      "    -0.42068047344660153 0.18660597143486746 -0.19690647337040723 -0.37443368747156636 -0.1736658051110329 \n",
      "    0.38943503419067743 -0.26711082504639777 0.48180860242033235 0.17736717635952665 0.02682461737714874 \n",
      "    0.46018610622080786 0.17866703114814883 0.46946915541241613 0.3678989310040223 0.08199699748397346 \n",
      "    0.3283188486657968 -0.4173239140224962 0.209856300686346 -0.16697852367515117 0.4849675206668313 \n",
      "    -0.0738967734144661 0.3606372417287689 0.001619584832998404 0.11780323123885705 -0.05710888744733444 \n",
      "    0.2524579867124089 0.07495551415536965 0.36793527940901166 0.05288107766075394 -0.45512159133937163 \n",
      "    -0.015859487267717562 0.08630641025923304 0.35836175054831443 -0.2775007648302753 0.17911620760260785 \n",
      "    -0.08998082809883391 0.13909378738857614 0.1055509398092168 0.17217669639389943 0.22577548009899062 \n",
      "    0.4269632329123451 0.04360836604268965 0.41112891994748463 0.17665018076285519 -0.09522536372914252 \n",
      "    -0.3428225668775701 0.3162109840088371 0.06699982273653268 0.45575130663404934 0.4178371386156819 \n",
      "    0.473042476123305 0.2960821388563048 -0.3241790881460401 -0.4383783033462934 -0.3498308233928072 \n",
      "  biases:\n",
      "    -0.1409752749501895    -0.15300807226791457    0.024184161144217665    0.13207270557401038    0.008715390711904887    0.11297192827959845    0.4826569336916569    0.48593555611166506    -0.12569263314750867    0.32867966253367403    -0.00830922579927166    -0.2414200276090593\n",
      "  weigh's gradient:\n",
      "    -0.047356498911644486 -0.047356498911644486 -0.047356498911644486 -0.047356498911644486 -0.047356498911644486 \n",
      "    0.03350205541057552 0.03350205541057552 0.03350205541057552 0.03350205541057552 0.03350205541057552 \n",
      "    0.11979881801767035 0.11979881801767035 0.11979881801767035 0.11979881801767035 0.11979881801767035 \n",
      "    0.05010062572136939 0.05010062572136939 0.05010062572136939 0.05010062572136939 0.05010062572136939 \n",
      "    0.1514569931993364 0.1514569931993364 0.1514569931993364 0.1514569931993364 0.1514569931993364 \n",
      "    -0.08591952511244308 -0.08591952511244308 -0.08591952511244308 -0.08591952511244308 -0.08591952511244308 \n",
      "    -0.04338008630565804 -0.04338008630565804 -0.04338008630565804 -0.04338008630565804 -0.04338008630565804 \n",
      "    0.038276708609878723 0.038276708609878723 0.038276708609878723 0.038276708609878723 0.038276708609878723 \n",
      "    0.0535689844489231 0.0535689844489231 0.0535689844489231 0.0535689844489231 0.0535689844489231 \n",
      "    0.061241792958621206 0.061241792958621206 0.061241792958621206 0.061241792958621206 0.061241792958621206 \n",
      "    0.08660590051559083 0.08660590051559083 0.08660590051559083 0.08660590051559083 0.08660590051559083 \n",
      "    -0.0037166796325289195 -0.0037166796325289195 -0.0037166796325289195 -0.0037166796325289195 -0.0037166796325289195 \n",
      "  biases gradient:\n",
      "    -0.047356498911644486    0.03350205541057552    0.11979881801767035    0.05010062572136939    0.1514569931993364    -0.08591952511244308    -0.04338008630565804    0.038276708609878723    0.0535689844489231    0.061241792958621206    0.08660590051559083    -0.0037166796325289195\n",
      "[1]\n",
      "  Dense layer:\n",
      "    neuron count=10\n",
      "  weight matrix:\n",
      "    0.4363302853819845 0.2784697831711057 0.41191644348177636 0.24278845947213712 0.23597335088006421 -0.18191024496828645 -0.33814682445242605 0.08207270925446586 0.0800764406478518 0.492646563731474 0.37465795829378545 0.027069768575826436 \n",
      "    0.17736910142411288 0.08164101059855966 0.41556286240115514 0.2984167974472306 0.198132084916119 0.49989531405470555 -0.07082386321936829 0.3427750507298485 -0.14568102250067194 0.30705844986707787 0.04986084640167965 -0.4187035058690194 \n",
      "    -0.1713446083529624 -0.18365678191985602 0.2420593500843753 0.2493534046708522 0.20416563204323712 -0.0622322605809188 -0.12099007453710497 0.3837270892984114 -0.17593950803430802 -0.17064664421233067 0.12831843883011462 -0.28949799031773327 \n",
      "    0.44829961427072385 -0.19942906325798881 -0.13240774303117264 -0.03796111130530422 -0.4043753781093864 0.4466760078333504 0.1193190171011973 0.2813024504022805 0.17819231162254634 -0.4967774005158577 0.018272372799435388 0.3787268033167731 \n",
      "    0.44687215543978664 -0.07881253907816965 0.17331469331576232 -0.30429354615113025 -0.42424154974389083 0.2240989473021553 0.31982798455395534 -0.44148635098973965 -0.38687507973017454 -0.2119766335334322 0.04833341885508058 -0.3257235227643235 \n",
      "    0.007689148041420291 -0.3181867386039462 -0.4221702379093496 -0.23699253440643764 0.20155354958694205 -0.22577533931428817 0.012744117649783115 0.44494445708255015 -0.30639917151653984 -0.08371919435059438 -0.15615371876529016 -0.3920360568888247 \n",
      "    -0.3737171569216716 -0.17912966437970124 0.3061891646731817 -0.016696046918072138 0.2809845373968308 -0.32666146956324016 0.38110818201343655 -0.40258014010440224 -0.025564323700018265 -0.3276421319403985 0.17620228611975308 -0.42005911332826384 \n",
      "    0.1702602611970231 0.0068578933445749835 -0.3643083416462102 -0.10752293763071408 -0.2365463189661171 0.3106006342253421 -0.10071565022868068 -0.07372075148209323 -0.3198041656816759 -0.03757826872311232 -0.48987790806432885 -0.2676542134884935 \n",
      "    0.3830076799826774 -0.13200834607834 0.14812622054336533 -0.38583317335113965 0.3531898506801754 -0.41897213480192774 0.2993308411575698 -0.06572247306154688 0.019833727175351812 -0.3975874916208123 0.2055348014386008 0.20566972906236514 \n",
      "    -0.2898737840743987 0.14131500854078394 -0.26798001965731755 -0.04948058716178705 -0.3152676401516751 -0.36149942133247537 -0.36484282121923584 -0.2815267737831161 -0.18922223197910504 0.060134586626186204 -0.26113076622406173 0.32321165999002055 \n",
      "  biases:\n",
      "    -0.40757244960742756    0.4173609704575125    0.4077683813731965    0.3644454416644727    0.019630499637688703    -0.37082862508996517    0.37392657027781384    -0.08361503581655916    0.26033262477530905    -0.3420957588011456\n",
      "  weigh's gradient:\n",
      "    0.13066883781953148 0.08608050162520982 0.24612792158872865 0.29802620816574915 0.21555017986854866 0.2164049393570533 0.24163048945864343 0.2448110729840245 0.2136664417991745 0.27694010641832323 0.2514546110028032 0.1263005365381816 \n",
      "    0.043298751925328595 0.028523849662040017 0.08155756182270223 0.09875470747231431 0.07142524508007222 0.07170848031554358 0.0800672814976372 0.08112120758545825 0.07080104493626459 0.09176756421865662 0.08332262690916016 0.041851260720290946 \n",
      "    0.1421036284893075 0.09361338041451255 0.26766650192906344 0.3241063919444484 0.2344129112340296 0.23534247046811363 0.26277550086688073 0.26623441629929767 0.23236432781315908 0.30117505177945564 0.2734593283305732 0.13735305847756807 \n",
      "    -0.14644977272406953 -0.09647648291168581 -0.27585290249156175 -0.3340189687151737 -0.24158227301278404 -0.242540262193021 -0.270812313440004 -0.2743770174826411 -0.23947103504101505 -0.3103862888805824 -0.28182289860601656 -0.14155390971251125 \n",
      "    -0.14249327476066495 -0.09387006706646828 -0.2684004399400256 -0.32499508738795546 -0.23505566833876643 -0.2359877764119858 -0.2634960278175671 -0.2669644275503887 -0.2330014677292288 -0.30200086979127777 -0.2742091501949736 -0.13772967874873415 \n",
      "    -0.10142879546471804 -0.06681808561657444 -0.19105135572919132 -0.23133625289388554 -0.16731605998107588 -0.16797954813003152 -0.1875603235041333 -0.19002918112342185 -0.1658538499657734 -0.21496863275600897 -0.19518608058096076 -0.09803799820511255 \n",
      "    0.017331010690810156 0.011417122236881324 0.032644704824362804 0.03952813452734458 0.028589084697204534 0.02870245408259545 0.0320481965395386 0.03247004713529828 0.028339238711246516 0.03673141986369334 0.03335120005859341 0.01675162942844434 \n",
      "    -0.10575016054971374 -0.06966486439282599 -0.19919108226647833 -0.24119231400127703 -0.17444454628960918 -0.17513630229394128 -0.19555131491448874 -0.19812535799976785 -0.17292003894268498 -0.22412735281873727 -0.20350196671403747 -0.10221489866523695 \n",
      "    0.06566437317887233 0.04325761425956004 0.12368546290481161 0.1497656555047044 0.10831937963058698 0.10874891774363632 0.12142539029174958 0.12302371340399493 0.10737275393449357 0.13916935973032132 0.1263622581325829 0.06346919206084276 \n",
      "    -0.04795428442243043 -0.031590767370732534 -0.09032672634977193 -0.10937292923242467 -0.0791049710490146 -0.0794186600685889 -0.08867620933947641 -0.08984345479409714 -0.07841365617499016 -0.1016345201562461 -0.09228157330069736 -0.0463511572684411 \n",
      "  biases gradient:\n",
      "    0.3529523107164816    0.1169551577728973    0.38383906119811356    -0.3955785216231384    -0.38489154283132143    -0.2739714252445165    0.046813152794867516    -0.28564395419365496    0.17736740168487286    -0.1295303132566951\n",
      "[2]\n",
      "  Softmax layer:\n",
      "  dimension: 10\n"
     ]
    }
   ],
   "source": [
    "target_vector = np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])   # one hot enc vector\n",
    "input_vector = np.array([1, 1, 1, 1, 1])\n",
    "\n",
    "net.loss_function = log_loss\n",
    "net.train_step(input_vector, target_vector, Adam(), 0.001)\n",
    "net.print_net_config(ConfigLevel.HIGH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.add_layer(Dense(neuron_count=12, act_function=sigmoid))\n",
    "net.add_layer(Dense(neuron_count=10, act_function=sigmoid))\n",
    "net.init_net(init_strategy=default_init, input_shape=(5, ))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers count=2\n",
      "layers:\n",
      "[0]\n",
      "  Dense layer:\n",
      "    neuron count=12\n",
      "  weight matrix:\n",
      "    0.42769451586462726 0.29369997309181284 0.4473857650092109 -0.2087147578892263 0.1672915281774711 \n",
      "    0.4923543144788477 0.2557950263949972 0.1563545339617518 0.19410080370301264 0.07603246043196266 \n",
      "    -0.18647304705116252 -0.1810950767465468 -0.1416633263461009 0.40680845025683243 -0.09381241951712938 \n",
      "    0.14951892423445465 -0.04652027073771684 -0.350698388558542 0.24647815006425963 -0.46219742627344035 \n",
      "    0.2887121861368657 -0.13522676147668206 -0.2413901477541997 0.02206878320646681 0.046276941793810186 \n",
      "    0.3399713711995385 0.3348394543743473 -0.38279361419932406 0.16277555479592026 -0.06837812503687339 \n",
      "    0.4985172071630435 -0.43727654403110205 -0.02781217888523146 -0.3839028223087432 0.326628068471693 \n",
      "    -0.010422285486544784 0.03824797097946896 -0.12389561676826333 -0.2855563449793339 0.4708173008677493 \n",
      "    -0.20652609450169285 0.0909297866389401 0.32188721359149125 -0.25334643805956786 0.24202440087982507 \n",
      "    0.3206538768644547 0.167559702698422 0.32059056210582204 0.32022679988887626 -0.3747649508826374 \n",
      "    0.0635176398532096 -0.20464014435370978 0.04082076254618141 -0.3466931693589309 -0.4322995999960553 \n",
      "    0.06020677842923715 -0.38289366410323966 -0.3278979209005085 -0.4889401505148969 -0.31382674593469595 \n",
      "  biases:\n",
      "    0.042252158601038176    -0.03072648340169448    -0.32696955223521784    -0.15644558832717617    0.3808365534206946    0.3260484598966141    -0.10759002468087353    -0.31726113320816596    -0.22440632910603658    0.004640778371506878    0.2275517413464049    0.14423929148518785\n",
      "  weigh's gradient:\n",
      "    0.06648801283963175 0.06648801283963175 0.06648801283963175 0.06648801283963175 0.06648801283963175 \n",
      "    -0.011523119056352164 -0.011523119056352164 -0.011523119056352164 -0.011523119056352164 -0.011523119056352164 \n",
      "    -0.02822039264487055 -0.02822039264487055 -0.02822039264487055 -0.02822039264487055 -0.02822039264487055 \n",
      "    -0.01604045772440637 -0.01604045772440637 -0.01604045772440637 -0.01604045772440637 -0.01604045772440637 \n",
      "    0.019545696589868263 0.019545696589868263 0.019545696589868263 0.019545696589868263 0.019545696589868263 \n",
      "    -0.0061432514710842 -0.0061432514710842 -0.0061432514710842 -0.0061432514710842 -0.0061432514710842 \n",
      "    0.007868351704826674 0.007868351704826674 0.007868351704826674 0.007868351704826674 0.007868351704826674 \n",
      "    -0.038440833882221415 -0.038440833882221415 -0.038440833882221415 -0.038440833882221415 -0.038440833882221415 \n",
      "    0.015097807808742043 0.015097807808742043 0.015097807808742043 0.015097807808742043 0.015097807808742043 \n",
      "    0.11439061181692851 0.11439061181692851 0.11439061181692851 0.11439061181692851 0.11439061181692851 \n",
      "    -0.03165432989736307 -0.03165432989736307 -0.03165432989736307 -0.03165432989736307 -0.03165432989736307 \n",
      "    0.04912799295164021 0.04912799295164021 0.04912799295164021 0.04912799295164021 0.04912799295164021 \n",
      "  biases gradient:\n",
      "    0.06648801283963175    -0.011523119056352164    -0.02822039264487055    -0.01604045772440637    0.019545696589868263    -0.0061432514710842    0.007868351704826674    -0.038440833882221415    0.015097807808742043    0.11439061181692851    -0.03165432989736307    0.04912799295164021\n",
      "[1]\n",
      "  Dense layer:\n",
      "    neuron count=10\n",
      "  weight matrix:\n",
      "    -0.33279102732283317 -0.4642761538763499 0.3058762804344396 0.1735265225422723 0.3628310631845335 0.13214574573452365 0.23696932077114985 -0.042096851290101434 -0.0624434038461259 -0.04697950268627116 -0.3943036958080748 0.12182576783469856 \n",
      "    0.4661464725498936 -0.45347208713672926 0.25321422291264906 0.236894942059115 0.07612762891172331 -0.1794417753978872 -0.3228062669848232 0.32486393905052435 -0.030022345989671573 0.40189838372255127 0.08665463441332977 0.04277342588519484 \n",
      "    -0.4905136490715297 -0.3548334730116266 0.3999983906352791 -0.12657569712402106 -0.061150821113615805 0.344340522955359 -0.15185549591102399 0.21135586680916518 0.2938986118488558 -0.3074735969177128 -0.04032237599862243 0.30893190244023994 \n",
      "    -0.06106151520681302 0.27436503901555165 -0.28017882103553005 0.17381053484530173 0.2562151705757145 0.44079310741610567 0.06088482420191199 -0.13877431105797733 -0.27870775755062793 0.33588707737285706 0.03642796213492472 0.293322603220759 \n",
      "    0.4574948796684086 0.12430974135642137 -0.02630622528510007 0.328609753321649 -0.30789063827256047 -0.09010860890782912 0.31100711332066455 0.0598231926353463 0.004660743685086954 0.0949475205353284 0.36378256878269033 0.29099296386192175 \n",
      "    0.25853717593956316 -0.3823405451593167 -0.12670401771280715 -0.4575296078547332 -0.1786841015452897 0.27878712021640095 0.15607290906745952 0.11150562292863864 0.4995981899860372 0.04697635521921839 -0.027973002270704428 0.2477986469716612 \n",
      "    0.30297435534933537 0.37930255736234175 0.05312591300574898 -0.1443805217496016 -0.3151778718137268 -0.13587585672513758 -0.2259477134030341 0.10042039628555899 -0.31115741405669006 -0.05354909150010545 0.38465379026225277 -0.4995973672882138 \n",
      "    -0.158453614090027 -0.38882057315306096 -0.12204866997103181 -0.35320916294949956 0.0640886543582122 -0.24885463668554153 0.2728881121093033 -0.380662042997562 -0.43474073258344703 0.3361745800528313 -0.495760422003234 0.19072448562436195 \n",
      "    -0.11422103917838 -0.4077408074281855 0.4419464729902478 0.18335120453137366 -0.3546925911674933 0.34980617478721765 0.12003336361550165 -0.1261407370905796 -0.32766379378431976 0.3710695920512681 0.17572778064603312 -0.0422317659887218 \n",
      "    0.3588554597292639 0.46297361701555895 0.3606354975321522 0.26401018402336107 -0.1984584299925335 -0.19410934097178756 0.11825377702754747 -0.44014948974440826 0.26817199590547325 0.44587741604838804 -0.00037464200264913927 0.22987123096422546 \n",
      "  biases:\n",
      "    0.1897843420047407    0.0028850387607664008    -0.25410305137524436    0.12374505561859661    -0.48141941728390936    -0.47091727167695396    0.46721208528788716    0.04687155045676572    0.11056405439524031    0.2580741092279758\n",
      "  weigh's gradient:\n",
      "    -0.09630705642629789 -0.09569543529473935 -0.046944003214677975 -0.044135680685321796 -0.0743744962649962 -0.08466144561163537 -0.05895529812356299 -0.05591459043147883 -0.06216984603399223 -0.08598456190897394 -0.04321994054133486 -0.026843944712831486 \n",
      "    0.29304916951832816 0.29118809026501036 0.14284416600828234 0.13429882555758285 0.22631139578521708 0.2576131723608175 0.1793928897311613 0.1701404330890545 0.18917431832511983 0.2616392338613885 0.13151235384254986 0.0816824435986303 \n",
      "    -0.11264995230280582 -0.11193454167918049 -0.05491019992998368 -0.051625317069661066 -0.08699553041794798 -0.0990281311041408 -0.06895976025079271 -0.06540305745879957 -0.07271980320322229 -0.10057577458237668 -0.050554179736948195 -0.03139924740440815 \n",
      "    0.27434445180206063 0.27260216135861437 0.13372672060827592 0.12572681142831663 0.2118664110712364 0.24117026048728668 0.16794261547089925 0.15928072385225617 0.17709971586419254 0.24493934687340743 0.12311819439528025 0.07646882346655971 \n",
      "    -0.08221548131806448 -0.08169335212440705 -0.040075192436653306 -0.03767778151978994 -0.06349207664647867 -0.07227384740359576 -0.050329003827337085 -0.047733210167673575 -0.05307320153706744 -0.07340336633255103 -0.03689603177585735 -0.022916159178117155 \n",
      "    0.2704692767805603 0.26875159656838454 0.131837801608805 0.12395089288511453 0.20887375195717295 0.23776367812985172 0.16557038951829342 0.15703084900177405 0.1745981438778675 0.24147952535140607 0.12137912313475757 0.07538868471152145 \n",
      "    -0.07047548077887292 -0.07002790928306987 -0.03435263540394102 -0.032297563971143355 -0.054425693988201 -0.06195346742302839 -0.04314224869804385 -0.0409171226848566 -0.04549458733116981 -0.06292169613483269 -0.031627444570646646 -0.019643834832456693 \n",
      "    0.21124417738886128 0.20990262041885252 0.10296906281227426 0.09680916337634403 0.16313632526224647 0.18570017710455336 0.12931517083961486 0.12264554746071048 0.13636610307878447 0.18860235918956994 0.09480053824962222 0.05888070126069933 \n",
      "    -0.08982759121115722 -0.08925711948228873 -0.04378564652539701 -0.041166265791347224 -0.06937063694954253 -0.07896548819937743 -0.05498883068478075 -0.052152699484299236 -0.05798710626646356 -0.0801995862425785 -0.040312135944977595 -0.02503790461090957 \n",
      "    0.23934976058155907 0.23782971234379374 0.11666887502445737 0.10968941422501324 0.1848412622601968 0.21040718603149358 0.14652027602658682 0.1389632736105093 0.15450931962619055 0.21369549719726888 0.10741354584785094 0.066714651848983 \n",
      "  biases gradient:\n",
      "    -0.12618541883107176    0.38396493015095956    -0.1475985451129236    0.3594572489204523    -0.10772206450373101    0.35437983713696636    -0.0923398387345466    0.2767807052626305    -0.11769576020881295    0.3136057824507822\n"
     ]
    }
   ],
   "source": [
    "target_vector = np.array([1, -1, 1, -1, 1, -1, 1, -1, 1, -1])\n",
    "input_vector = np.array([1, 1, 1, 1, 1])\n",
    "\n",
    "net.loss_function = log_loss\n",
    "net.train_step(input_vector, target_vector, Adam(), 0.001)\n",
    "net.print_net_config(ConfigLevel.HIGH)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
